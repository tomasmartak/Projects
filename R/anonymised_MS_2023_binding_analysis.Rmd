---
title: "MS_2023_binding_analysis"
author: "Tom치코 Mar콘치k"
date: "2023-09-22"
output:
    rmdformats::downcute:
        df_print: paged
        code_folding: hide
        toc: 3
editor_options:
    markdown:
        wrap: sentence
---

# 1. Start analysis pipeline {.tabset .tabset-fade .tabset-pills}

```{r 0_setup, warning=FALSE, message=FALSE}
### Setup
## libraries
#core
library("conflicted")
library ("data.table"); setDTthreads(percent = 80)
library("furrr")
library("gghighlight")
library("ggplot2")
library("ggrepel")
library("magrittr")
library("openxlsx2")
library("progressr") # used for multithreaded web scraping
library("stringr")
library("xml2")

#bioconductor
library("imputeLCMD")
library ("limma")
library("ROTS")


## pop flag so that r_variables doesn't set off its inbuilt code looper
flag <- "exists"


## source variables
source("~/Documents/MS/scripts/r_variables_MS.R")


## progressr/knittr options
handlers("cli")
```

Inspiration: - [TowardsDataScience](https://towardsdatascience.com/embrace-r-to-boost-your-proteomic-analysis-ea6fdc8909e7) - [Proteus](https://github.com/bartongroup/proteus) - [Guide for protein FC and p calculations for the uninitiated](https://doi.org/10.1039/D0MO00087F) - and many, many others (see some below).

## 1.1 Convert MaxQuant files into wide format

**Synthesising protein-level intensity**: protein-level intensity can be synthesised in multiple ways if not done already by your software of choice (e.g. MaxQuant's MaxLFQ does this for proteinGroups.txt, but there are only peptide-level IDs for evidence.txt). One might use e.g. sums, means, or medians of peptide-level intensities, as well as more sophisticated methods. The default I'm using is sums ([reason](https://doi.org/10.1093/bioinformatics/btp610)) - this is also call total ion current (TIC), as it is effectively the sum of peptide intensities generated by MaxQuant via XIC (eXtracted Ion Current of all isotopic clusters associated with a unique amino acid sequence).

This should effectively be very similar to the [ICan](https://doi.org/10.1021/pr5008224) procedure (conveniently enough, this has actually been done on LF-DDA (lable-free, data-dependent acquisition) LC-MS/MS (liquid chromatography tandem mass spectrometry), unlike the link above), which has been described to outperform simple "Sum-of-Intensity" and "iBAQ" methods when used from bottom up. Here, however, I already use XIC values from MaxQuant, so this is probably my easiest bet.

Unfortunately, 2 replicates is simply not enough, despite using a pretty robust method. An minimum number of replicates for any sort of accurate identification would start at 5/6 for label-free data-dependent acquisition liquid chromatography tandem MS (LF-DDA LC-MS/MS), as described [here](https://10.1021/acsomega.0c04030).

**Log2 transformation**: performed before normalisation and optional imputation (once; [reason for both](https://doi.org/10.1186/1471-2105-13-S16-S5)).

**Normalisation**: Performed before, not after, imputation and plotting.
Type chosen (given LC-MS/MS): LoessF ([reason](https://doi.org/10.1093/bib/bbw095); also, Rlr via NormalyzerDE doesn't allow IgG shennanigans).

**Imputation:** QRILC (given LC-MS/MS; [reason](https://doi.org/10.1038/s41598-017-19120-0)).
This showed the most stable performance of all imputation models used, and furthermore worked better with log2 transformation.

```{r 1_concatenate_and_convert_to_wide, warning=FALSE, message=FALSE, results='hide'}
### Setup
## setup output directories if not already existing
if (dir.exists(out_wide_evi) == F) dir.create(out_wide_evi, recursive = T)
if (dir.exists(out_wide_pg) == F) dir.create(out_wide_pg, recursive = T)

### Setup functions ################################################################################################################
## def function for cleaning evidence.txt files and concatenating into tsv
evi_to_combined_tsv <- function (input_list, outputID, writefile = F, verbose = F, intensity_calc_method = "sum",
                                 unique_peptides_min = 2, peptide_length_min = 6, peptide_length_max = 25) {
    # # toy data
    # outputID <- "MaxQuant"
    # writefile <- outdir
    # input_list <- maxquant_evidence_list
    # intensity_calc_method <- "sum"
    # unique_peptides_min <- 3
    # peptide_length_min <- 6
    # peptide_length_max <- 25
   
    cat("\nThe following method was chosen for protein-level intensity calculation from peptide intensities:", intensity_calc_method)
    
    # Initialize an empty data frame to store the combined data
    temp_combined <- data.table()
    
    for (file in input_list) {
        # setup
        temp_dt <- fread(file)
        
        # modify eperiment names based on pattern
        pattern = "(PLK\\d{3})_.*(_\\w{3,5})_2uL_DDA-*(Faims)*_.*$"
        temp_dt$Experiment <- str_replace(temp_dt$`Raw file`, pattern, "\\1\\3\\2")
        
        # clean data into useful stuff
        temp_dt <- temp_dt[!is.na(Intensity)] %>% # remove peptides with NA intensities
            .[`Potential contaminant` == "" & Reverse == ""] %>% # remove contaminants/decoys
            .[Length >= peptide_length_min & Length <= peptide_length_max] %>% # remove peptides of unsuitable length
            setnames(x = ., old = c("Sequence", "Leading razor protein", "Experiment", "Intensity"), # rename
                     new = c("sequence", "protein_main", "experiment", "intensity")) %>%
            .[order(experiment), .(sequence, intensity, protein_main, experiment)] # order and subset
        
        # prepare descriptors in case of verbose option
        if (verbose) {
            temp_dt_og <- fread(file)
            cat("\n", rep("-", 40), "\nFile:", file, "\n", rep("-", 40),
                "\nNumber of rows before filtering:", nrow(temp_dt_og),
                "\nPeptides with missing intensities removed:", nrow(temp_dt_og[is.na(Intensity)]),
                "\nContaminant and decoy sequences removed:", nrow(temp_dt_og[!is.na(Intensity)][`Potential contaminant` == "+" | Reverse == "+"]),
                "\nPeptides with unsuitable length removed:", nrow(temp_dt_og[!is.na(Intensity)][`Potential contaminant` == "" & Reverse == ""][Length < peptide_length_min | Length > peptide_length_max]),
                "\nTheoretical number of rows after filtering:",
                (nrow(temp_dt_og) - nrow(temp_dt_og[is.na(Intensity)]) -
                     nrow(temp_dt_og[!is.na(Intensity)][`Potential contaminant` == "+" | Reverse == "+"]) -
                     nrow(temp_dt_og[!is.na(Intensity)][`Potential contaminant` == "" & Reverse == ""][Length < peptide_length_min | Length > peptide_length_max])),
                "\nActual number of rows after filtering:", nrow(temp_dt), "\n\n")
        }
      
        # make experiment names nicer
        temp_dt$experiment <- str_replace_all(temp_dt$experiment,
                                              c("PLK089Faims_PA1" = "89FAIMS_C-1", "PLK089Faims_PA2" = "89FAIMS_C-2",
                                                "PLK089Faims_PA3" = "89FAIMS_T-1", "PLK089Faims_PA4" = "89FAIMS_T-2",
                                                "PLK089Faims_PA5" = "89FAIMS_IgG-1", "PLK089_PA1" = "89_C-1",
                                                "PLK089_PA2" = "89_C-2", "PLK089_PA3" = "89_T-1", "PLK089_PA4" = "89_T-2",
                                                "PLK089_PA5" = "89_IgG-1", "PLK099_DPNC1" = "99_H1299-1",
                                                "PLK099_DPNC2" = "99_H1299-2", "PLK099_DPNC3" = "99_PANC1-1", "PLK099_DPNC4" = "99_PANC1-2"))
      
        # sum up intensities to leave single intensity per unique protein; filter out proteins with insufficient unique peptides
        if (intensity_calc_method %in% c("sum", "average", "median")) {
            temp_dt <- temp_dt[, .SD[.N >= unique_peptides_min], by = .(experiment, protein_main)][
                , .(intensity = switch(
                    intensity_calc_method,
                    "sum" = sum(intensity),
                    "average" = mean(intensity),
                    "median" = median(intensity),
                    )), by = .(experiment, protein_main)]
        } else {
            cat("\nPlease use a valid method for calculating protein-level intensities: sum, average, or median. \nLocation: `evi_to_combined_tsv()`.\n")
        }
    
        # create master column --> master experiment
        temp_dt[, experiment_master := str_extract(string = experiment, pattern = "^(\\d{2})(FAIMS)?")] # extract the master experiment
     
        # Combine the data with the existing combined data
        temp_combined <- rbindlist(list(temp_combined, temp_dt), fill = TRUE)
    }
  
    # write evi to keep for later
    if (is.null(writefile)) fwrite(x = temp_combined, file = paste0(writefile, outputID, unique_peptides_min,"-unique-peptides_pre.tsv"), sep = "\t")
    
    # return
    return (temp_combined)
}

# ----------------------------------------------------------------------------------------------------------------------------------
## def function for cleaning files and converting into tsv
pg_to_combined_tsv <- function (input_list, outputID, writefile = F, verbose = F,
                                unique_peptides_min, protein_choice) {
    # Initialize an empty data frame to store the combined data
    temp_combined <- data.table()
    
    # loop through inputs
    for (file in input_list) {
    	# # toy data
    	# file <- mq_pg_list_89[2]
    	# file <- mq_pg_list_99[1]
        
    	# load data
    	temp_dt <- fread(file)
     	 
    	## prefilter data
    	# define column groups
    	main_columns <- c("Protein IDs", "Peptide counts (unique)", "Number of proteins", "Peptide IDs", "Evidence IDs", "Fasta headers")
    	unique_peptides_columns <- grep("Unique peptides ", names(temp_dt), value = T)
    	intensity_columns <- grep("LFQ intensity ", names(temp_dt), value = T)
    	temp_name <- str_extract(string = file,
                             	pattern = "raw\\/(.*)__A.*5x_*(\\w{0,5})\\/",
                             	group = c(1,2))
    	
    	temp_name <- paste0(temp_name[1], temp_name[2])
    	
    	# handle temp_name if plk99
    	if (length(grep(x = temp_name, pattern = "NA")) > 0) temp_name <- str_extract(string = file, pattern = "raw\\/(.*)__A.*4x", group = 1)
        
    	# filter
    	temp_dt <- temp_dt[`Potential contaminant` == "" & Reverse == "" & `Q-value` <= 0.01 & `Unique peptides` >= unique_peptides_min,
                       	c(main_columns, unique_peptides_columns, intensity_columns),
                       	with = FALSE]
    	
    	## reshape data
    	# Use melt to reshape the data for unique peptides
    	melted_peptides <- melt(temp_dt, id.vars = main_columns,
                            	measure.vars = unique_peptides_columns,
                            	variable.name = "sample", value.name = "unique_peptides") %>%
    	    .[, sample := paste0(temp_name, "_", gsub("^.*\\s{1}(PA|DPNC\\d{1}_*.*)$", "\\1", sample))]
        
    	# Use melt to reshape the data for intensity
    	melted_intensity <- melt(temp_dt, id.vars = main_columns,
                            	measure.vars = intensity_columns,
                            	variable.name = "sample", value.name = "intensity") %>%
    	    .[, sample := paste0(temp_name, "_", gsub(".*(PA|DPNC\\d{1})_*.*$", "\\1", sample))]
    
    	# Merge the two melted data.tables by 'Protein IDs', 'Peptide counts (unique)', and 'sample'; filter
    	temp_dt <- melted_peptides %>%
    	    .[, intensity := melted_intensity$intensity] %>%
    	    .[unique_peptides >= unique_peptides_min]
       
    	# Further filtering - choose 1 protein per protein groups
    	filter_IDs <- which(temp_dt$`Number of proteins` > 1) # ambiguous proteins
    	if (protein_choice %in% c("1", "Quantity", "quantity", "First", "first", "One", "one")) {
      	# for each row ID, update the 'Protein IDs' column to leave only the 1st one
    	    for (rowID in filter_IDs) {
        	    temp_dt[rowID, `Protein IDs` := sub(";.*", "", `Protein IDs`)]
      	    }
        } else if (protein_choice %in% c("2", "Quality", "quality","Conservation", "conservation", "Two", "two")) {
          	# setup empty data table for appending
          	temp_dt_quality <- data.table()
         	 
          	# generate ID column for temp_dt
          	temp_dt_filtered <- temp_dt[, row_id := seq_along(1:nrow(temp_dt))]
         	 
          	# filter grouped proteins
          	for (rowID in filter_IDs) {
            	# # toy data
            	# rowID <- 58
           	    
            	# extract individual IDs and unique peptide counts
            	temp_IDs <- unlist(strsplit(temp_dt[rowID, `Protein IDs`], ";"))
            	temp_peptCounts <- unlist(strsplit(temp_dt[rowID, `Peptide counts (unique)`], ";"))
           	 
               	# get list containing indexes of proteins with peptide counts larger than the threshold set by unique_peptides_min
               	passing_proteins <- which(as.numeric(temp_peptCounts) >= unique_peptides_min)
               	 
               	# create new dt to store new uniprot IDs/unique peptide counts in; if passing_proteins > 1, split into multiple rows
               	if (length(passing_proteins) > 1) { # if there are more proteins in the group
                 	for (i in passing_proteins) {
                 	    # # toy data
                 	    # i <- 1
                 	    temp_row <- temp_dt[rowID,] %>%
                 	        .[, `:=` (`Protein IDs` = temp_IDs[i],
                 	                  `Peptide counts (unique)` = temp_peptCounts[i],
                 	                  `Number of proteins` = length(passing_proteins))]
                 	    temp_dt_quality <- rbindlist(list(temp_dt_quality, temp_row))
                	}
               	} else { # overwrite with main protein
        	        temp_row <- temp_dt[rowID,] %>%
                 	        .[, `:=` (`Protein IDs` = temp_IDs[1],
                 	                  `Peptide counts (unique)` = temp_peptCounts[1],
                 	                  `Number of proteins` = length(passing_proteins))]
             	    temp_dt_quality <- rbindlist(list(temp_dt_quality, temp_row))
        	    }
          	}
           	# make new temp_dt with filtered out proteins
  	        temp_dt <- rbindlist(list(temp_dt_filtered[`Number of proteins` == 1], temp_dt_quality))
    	    
    	    # do protein counts across samples
    	    temp_dt[, protein_count := .N, by = .(sample, `Protein IDs`)]
      	    
  	        # if any protein counts are higher than 1, throw error; done to see if this can even be the case;
    	            # later, if this can be the case, intra-sample protein count abundance can be used as a further filter
  	        if (length(unique(temp_dt$protein_count)) > 1) {
                stop (paste0("\nThere are ambiguously-assigned proteins in your data, check what's up with this. \nError location: `pg_to_combined_tsv()`"))
  	        } else {
    	        for (rowID in filter_IDs) {
      	            temp_dt[rowID, `Protein IDs` := sub(";.*", "", `Protein IDs`)]
    	        }
  	        }
        } else cat("Protein choosing method (", protein_choice, ") not found. Please choose a valid method.")
	    
    	# finish filtering data
	    temp_dt <- temp_dt[, .(`Protein IDs`, sample, intensity)] %>%
	        .[intensity > 0] %>% # remove missing intensity values
	        setnames(x = ., old = c("Protein IDs", "sample"), # rename
    	         new = c("protein_main", "experiment")) %>%
	        .[order(experiment), .(intensity, protein_main, experiment)] # order and subset
         
        # make experiment names nicer
        temp_dt$experiment <- str_replace_all(temp_dt$experiment,
                                              c("PLK089FAIMS_PA1" = "89FAIMS_C-1", "PLK089FAIMS_PA2" = "89FAIMS_C-2",
                                                "PLK089FAIMS_PA3" = "89FAIMS_T-1", "PLK089FAIMS_PA4" = "89FAIMS_T-2",
                                                "PLK089FAIMS_PA5" = "89FAIMS_IgG-1", "PLK089_PA1" = "89_C-1",
                                                "PLK089_PA2" = "89_C-2", "PLK089_PA3" = "89_T-1", "PLK089_PA4" = "89_T-2",
                                                "PLK089_PA5" = "89_IgG-1", "PLK099_DPNC1" = "99_H1299-1",
                                                "PLK099_DPNC2" = "99_H1299-2", "PLK099_DPNC3" = "99_PANC1-1", "PLK099_DPNC4" = "99_PANC1-2"))
    
        # create master column --> master experiment
        temp_dt[, experiment_master := str_extract(string = experiment, pattern = "^(\\d{2})(FAIMS)?")] # extract the master experiment
    
        
        
        # Combine the data with the existing combined data
        temp_combined <- rbindlist(list(temp_combined, temp_dt), fill = TRUE)
    }
    
    # write file to keep for later
    if (is.null(writefile)) fwrite(x = temp_combined, file = paste0(writefile, outputID, unique_peptides_min,"-unique-peptides_pre.tsv"), sep = "\t")
    
    # return
    return (temp_combined)
}

# ----------------------------------------------------------------------------------------------------------------------------------
## define function: intensity_imputer
intensity_imputer <- function (input, imputation_mode = NULL) {
    # # toy data
    # input <- temp_subset
    # imputation_mode <- "razor"
    # row <- 382
    # col <- 5
    
    cat("\nPerforming imputation...")
    
    # create inner copy
    #temp_dt <- temp_subset
    temp_dt <- input

    # checks
    if (ncol(temp_dt) < 3) stop (paste0("\nThere are ", col(temp_dt), " columns in your data, which I consider to be too little for imputation. Check what's up with this. \nError location: `intensity_imputer()`"))
    
    # setup sorting information variables
    baseline <- grep(x = colnames(temp_dt), pattern = "IgG", value = T) # ID(s) of column(s) with baseline
    pids <- grep(x = colnames(temp_dt), pattern = "protein", value = T) # ID of column with protein IDs
    treatment <- grep(x = colnames(temp_dt), pattern = "_T-\\d{1}$", value = T) # IDs of columns with treatment (for plk89)
    control <- grep(x = colnames(temp_dt), pattern = "_C-\\d{1}$", value = T) # IDs of columns with control (for plk89)
    h1299 <- grep(x = colnames(temp_dt), pattern = "H1299", value = T) # IDs of columns with H1299 (for plk99)
    panc1 <- grep(x = colnames(temp_dt), pattern = "PANC1", value = T) # IDs of columns with Panc1 (for plk99)
    is_faims <- length(grep(x = colnames(temp_dt), pattern = "FAIMS")) > 0 # bool to check whether the current dataset is FAIMS or not
    if (length(baseline) > 1) stop (paste("\nError!", length(baseline),"IgG columns were detected, which is more than 1.\nError location: `intensity_imputer()`"))
    
    # Set functionality based on the presence or absence of an IgG column
    if (length(grep(x = colnames (temp_dt), pattern = "IgG")) == 0) {
        # drop all proteins where no non-NA values outside of IgG exist
        temp_dt <- temp_dt[rowSums(!is.na(temp_dt[,-..baseline][,-..pids])) > 0]
        
        # overlap_info: data on treatment/control overlap information; downstream: abundance of control vs treatment for Cyt domain
        overlap_info <- ifelse(test = is_faims, yes = "overlap_info_FAIMS", no = "overlap_info_classic")
        temp_dt[, paste(overlap_info) := ifelse(test = rowSums(!is.na(.SD[,..treatment])) > 0 & # at least 1 non-NA value present in treatment
                                                    rowSums(!is.na(.SD[,..control])) > 0, yes = "overlap", # at least 1 non-NA value present in control
                                                # EC domain information only (i.e. only in control); downstream: abundance against IgG baseline
                                                no = ifelse(test = rowSums(!is.na(.SD[, ..control])) > 0 & # at least 1 non-NA value present in control
                                                                rowSums(!is.na(.SD[, ..treatment])) == 0 & # only NA values in treatment
                                                                rowSums(!is.na(.SD[, ..baseline])) > 0, yes = "EC", # IgG values must be present
                                                            # RISKY EC domain information only (i.e. only in control, no IgG column); downstream: list
                                                            no = ifelse(test = rowSums(!is.na(.SD[, ..control])) > 0 & # at least 1 non-NA value present in control
                                                                            rowSums(!is.na(.SD[, ..treatment])) == 0 & # only NA values in treatment
                                                                            rowSums(!is.na(.SD[, ..baseline])) == 0, yes = "risky_EC", # IgG values missing
                                                                        # Cyt domain information only (i.e. only in treatment); downstream: abundance against IgG baseline
                                                                        no = ifelse(test = rowSums(!is.na(.SD[, ..treatment])) > 0 & # at least 1 non-NA value present in treatment
                                                                                        rowSums(!is.na(.SD[, ..control])) == 0 & # only NA values in control
                                                                                        rowSums(!is.na(.SD[, ..baseline])) > 0, yes = "Cyt", # IgG values must be present
                                                                                    # RISKY Cyt domain information only (i.e. only in template, no IgG column); downstream: list
                                                                                    no = ifelse(test = rowSums(!is.na(.SD[, ..treatment])) > 0 & # at least 1 non-NA value present in treatmnet
                                                                                                    rowSums(!is.na(.SD[, ..control])) == 0 & # only NA values in control
                                                                                                    rowSums(!is.na(.SD[, ..baseline])) == 0, # IgG values missing
                                                                                                yes = "risky_Cyt", no = "")))))]
        
        # set backup for column order
        og_colorder <- colnames(temp_dt)
    
        # perform imputation
        if (imputation_mode == "QRILC") {
            # setup
            cat("\nQRILC imputation chosen. Imputing...")
            
            # cycle through categories and impute
            for (category in c("overlap", "EC", "Cyt")) {
                # # toy data
                # category <- "Cyt"
                temp_ols <- grep(pattern = category, x = unique(temp_dt[[overlap_info]]), value = T) # temporary overlap colnames 
                temp_ol_cols <- list("overlap" = c(control, treatment), "EC" = control, "Cyt" = treatment) %>% 
                    .[[category]] # load cols to impute
                
                temp_dt_remainder <- temp_dt[!temp_dt[[overlap_info]] %in% temp_ols]
                temp_dt_ol_remainder <- temp_dt[temp_dt[[overlap_info]] %in% temp_ols][, !temp_ol_cols, with = FALSE]
                temp_dt_ol_imputed <- temp_dt[temp_dt[[overlap_info]] %in% temp_ols][, temp_ol_cols, with = FALSE]
                
                # special case for low number of rows/high N of NAs - copy neighbour without imputing
                if (nrow(temp_dt_ol_imputed) < 3 | # < 3 rows or more than nrows - 2 NAs (need 2 values for QRILC)
                    !all(apply(temp_dt_ol_imputed, 2, function(x) sum(is.na(x)) > (nrow(temp_dt_ol_imputed) - 2)))) {
                    # do duplicate of value above instead, if not present, of value in neighbouring cell
                    na_indices <- which(is.na(temp_dt_ol_imputed), arr.ind = TRUE)
                    
                    for (i in 1:nrow(na_indices)) {
                        # # toy data
                        # i <- 1
                        na_row <- unname(na_indices[i,])[1]
                        na_col <- unname(na_indices[i,])[2]
                        
                        # copy neighbour
                        temp_dt_ol_imputed[[na_row, na_col]] <- as.numeric(temp_dt_ol_imputed[na_row, ifelse(na_col %% 2 == 0, na_col - 1, na_col + 1), with = F])  
                    }
                    temp_dt <- rbind(cbind(temp_dt_ol_imputed, temp_dt_ol_remainder), temp_dt_remainder) # can do this since row indexes should be same
                    next
                }
                
                # run if sufficient number of rows
                temp_dt_ol_imputed <- temp_dt_ol_imputed %>%
                    as.matrix() %>%
                    imputeLCMD::impute.QRILC(dataSet.mvs = .) %>%
                    as.data.table() %>%
                    .[, 1:(length(.)-1)] %>% # remove qvalues generated by QRILC imputation
                    magrittr::set_names(., colnames(temp_dt[temp_dt[[overlap_info]] %in% temp_ols][, temp_ol_cols, with = FALSE])) # replace colnames; named to satisfy conflict
                temp_dt <- rbind(cbind(temp_dt_ol_imputed, temp_dt_ol_remainder), temp_dt_remainder) # can do this since row indexes should be same
            }
            setcolorder(temp_dt, og_colorder)
            # razor    
        } else if (imputation_mode %in% c("Razor", "razor", "Nonfiction", "nonfiction", "Strict", "strict")) {
            cat("\nRazor imputation chosen. Discarding all proteins with missing values in sample repeat intensities (except IgG)...")
            
            # cycle through categories and impute
            for (category in c("overlap", "EC", "Cyt")) {
                # # toy data
                # category <- "Cyt"
                temp_ols <- grep(pattern = category, x = unique(temp_dt[[overlap_info]]), value = T) # temporary overlap colnames 
                list(temp_dt[[overlap_info]])
                
                temp_ol_cols <- list("overlap" = c(control, treatment), "EC" = control, "Cyt" = treatment) %>% 
                    .[[category]] # load cols to impute
                temp_dt_remainder <- temp_dt[!temp_dt[[overlap_info]] %in% temp_ols]
                temp_dt_imputed <- temp_dt[temp_dt[[overlap_info]] %in% temp_ols] %>% # filter part with overlap to contain only proteins with no missing intensity values
                    .[complete.cases(.[, temp_ol_cols, with = FALSE])] 
                temp_dt <- rbind(temp_dt_remainder, temp_dt_imputed) # add this back to the remainder of the data table (risky/IgG EC/Cyt)
            }
            # duplicate
        } else if (imputation_mode %in% c("Duplicate", "duplicate", "Squeeze", "squeeze", NULL)) {
            cat("\nImputation mode not chosen, defaulting to Duplicate/NULL. Filling in protein intensity NA values by copying the values from the average of the other intensity values in the repeats of the same sample...")
            
            # cycle through categories and impute
            for (category in c("overlap", "EC", "Cyt")) {
                # # toy data
                # category <- "EC"
                temp_ols <- grep(pattern = category, x = unique(temp_dt[[overlap_info]]), value = T) # temporary overlaps; adds risky_ too 
                temp_ol_cols <- list("overlap" = c(control, treatment), "EC" = control, "Cyt" = treatment) %>% 
                    .[[category]] # load cols to impute
                temp_dt_remainder <- temp_dt[!temp_dt[[overlap_info]] %in% temp_ols]
                temp_dt_ol_remainder <- temp_dt[temp_dt[[overlap_info]] %in% temp_ols][, !temp_ol_cols, with = FALSE]
                temp_dt_ol_imputed <- temp_dt[temp_dt[[overlap_info]] %in% temp_ols][, temp_ol_cols, with = FALSE] 
                
                # find and replace NA values with duplicates of the remaining non-NA values in the same replicates 
                na_indices <- which(is.na(temp_dt_ol_imputed), arr.ind = TRUE)
                for (na_colID in unique(na_indices[, 2])) {
                    # # test
                    # na_colID <- 4
                    
                    # grab NA value rowIDs for given column ID; unlist/list to preserve all ids, not just the 1st one
                    # why ifelse? bc if there is only 1 NA value in the given na_colID, [,1] indexing no longer works (nrow returns null)
                    # the indexing simply sucks... :(
                    na_row_ids <- unlist(ifelse(test = is.null(nrow(na_indices[na_indices[, 2] == na_colID, ])),
                                                yes = na_indices[na_indices[, 2] == na_colID, ][[1]],
                                                no = list(na_indices[na_indices[, 2] == na_colID, ][,1])))
                    
                    # CAUTION!!! THE CODE BELOW PRESUMES THAT ONLY ONE REPEAT IS PRESENT PER NON-IgG SAMPLE!!!-----------#
                    number_colID <- ifelse(test = (na_colID %% 2 == 0), # test if the col ID is even                     # 
                                           yes = na_colID - 1, no = na_colID + 1) # effectively switch even/odd IDs;     #
                    #----------------------------------------------------------------------------------------------------#
                    
                    # generate replacement values for NAs
                    replacement_values <- as.list(temp_dt_ol_imputed[na_row_ids, ..number_colID])[[1]] 
                    
                    # replace NA values in temp_dt_imputed
                    temp_dt_ol_imputed[na_row_ids, eval(na_colID) := replacement_values]
                }
                
                temp_dt <- rbind(cbind(temp_dt_ol_imputed, temp_dt_ol_remainder), temp_dt_remainder) # can do this since row indexes should be same
                setcolorder(temp_dt, og_colorder)
                
                # check if there are remaining NAs 
                if (length(which(is.na(temp_dt_ol_imputed), arr.ind = TRUE)) > 1) stop (paste0("\nThere is at least 1 NA value in groups post imputation. Check the code. \nLocation: intensity_imputer()."))
            } 
        } else stop(paste0("\nError! Please select a valid imputation method (QRILC, razor, duplicate/NULL). \nYou chose: ", imputation_mode,
                           ". \nError location: `intensity_imputer()`"))
    } else {
        # drop all proteins where no non-NA values exist
        temp_dt <- temp_dt[rowSums(!is.na(temp_dt[,-..pids])) > 0]
        
        # perform imputation
        if (imputation_mode == "QRILC") {
            # setup
            cat("\nQRILC imputation chosen. Imputing...")
            
            # run if sufficient number of rows
            temp_dt <- temp_dt %>%
                as.matrix() %>%
                imputeLCMD::impute.QRILC(dataSet.mvs = .) %>%
                as.data.table() %>%
                .[, 1:(length(.)-1)] %>% # remove qvalues generated by QRILC imputation
                magrittr::set_names(., colnames(temp_dt[temp_dt[[overlap_info]] %in% temp_ols][, temp_ol_cols, with = FALSE])) # replace colnames; named to satisfy conflict
        
        # razor    
        } else if (imputation_mode %in% c("Razor", "razor", "Nonfiction", "nonfiction", "Strict", "strict")) {
            cat("\nRazor imputation chosen. Discarding all proteins with missing values in sample repeat intensities...")
            temp_dt <- temp_dt[complete.cases(.[, temp_ol_cols, with = FALSE])] 
        
        # duplicate
        } else if (imputation_mode %in% c("Duplicate", "duplicate", "Squeeze", "squeeze", NULL)) {
            cat("\nImputation mode not chosen, defaulting to Duplicate/NULL. Filling in protein intensity NA values by copying the values from the average of the other intensity values in the repeats of the same sample...")
            
            # find and replace NA values with duplicates of the remaining non-NA values in the same replicates 
            na_indices <- which(is.na(temp_dt), arr.ind = TRUE)
            for (na_colID in unique(na_indices[, 2])) {
                # # test
                # na_colID <- 4
                
                # grab NA value rowIDs for given column ID; unlist/list to preserve all ids, not just the 1st one
                # why ifelse? bc if there is only 1 NA value in the given na_colID, [,1] indexing no longer works (nrow returns null)
                # the indexing simply sucks... :(
                na_row_ids <- unlist(ifelse(test = is.null(nrow(na_indices[na_indices[, 2] == na_colID, ])),
                                            yes = na_indices[na_indices[, 2] == na_colID, ][[1]],
                                            no = list(na_indices[na_indices[, 2] == na_colID, ][,1])))
                
                # CAUTION!!! THE CODE BELOW PRESUMES THAT ONLY ONE REPEAT IS PRESENT PER NON-IgG SAMPLE!!!-----------#
                number_colID <- ifelse(test = (na_colID %% 2 == 0), # test if the col ID is even                     # 
                                       yes = na_colID - 1, no = na_colID + 1) # effectively switch even/odd IDs;     #
                #----------------------------------------------------------------------------------------------------#
                
                # generate replacement values for NAs
                replacement_values <- as.list(temp_dt[na_row_ids, ..number_colID])[[1]] 
                
                # replace NA values in temp_dt_imputed
                temp_dt[na_row_ids, eval(na_colID) := replacement_values]
                
                # check if there are remaining NAs 
                if (length(which(is.na(temp_dt), arr.ind = TRUE)) > 1) stop (paste0("\nThere is at least 1 NA value in groups post imputation. Check the code. \nLocation: intensity_imputer()."))
            } 
        } else stop(paste0("\nError! Please select a valid imputation method (QRILC, razor, duplicate/NULL). \nYou chose: ", imputation_mode,
                           ". \nError location: `intensity_imputer()`"))
    }

    # return
    return (temp_dt)
}

# ----------------------------------------------------------------------------------------------------------------------------------
## define function: subtract_IgG
subtract_IgG <- function (input) {
    # setup main
    temp_dt <- input
    
    # setup cols
    baseline <- grep(x = colnames(temp_dt), pattern = "IgG") # column with baseline
    pids <- grep(x = colnames(temp_dt), pattern = "protein") # column with protein IDs
    treatment <- grep(x = colnames(temp_dt), pattern = "_T-\\d{1}$") # IDs of columns with treatment
    control <- grep(x = colnames(temp_dt), pattern = "_C-\\d{1}$") # IDs of columns with control
    overlap_info <- grep(x = colnames(temp_dt), pattern = "overlap_info") # IDs of columns with control
    temp_names <- names(temp_dt[, c(control, treatment), with = FALSE])
    
    # subset dataset for IgG subtraction
    temp_dt_remainder <- temp_dt[temp_dt[[overlap_info]] != "overlap"]
    temp_dt_main <- temp_dt[temp_dt[[overlap_info]] == "overlap"]
    
    # subtract IgG row from rest if present; NOTE: wouldn't it be easier to simply subset and do a areal discount of every intensity value?
    cat("\nDiscounting IgG from sample intensity values...")
    for (row in 1:nrow(temp_dt_main)) {
        # row <- 2
        for (col in temp_names) {
    	    # col <- '89_C-1'
            if (is.na(temp_dt_main[row, ..baseline])) next
            temp_dt_main[row, eval(col)] <- temp_dt_main[row, get(col)] - temp_dt_main[row, ..baseline]
            
      }
    }

    # remove rows where the largest number is <0 (i.e. where all IgG values are > sample values)
    temp_dt_main <- temp_dt_main[!apply(temp_dt_main[, c(control, treatment), with = FALSE], 1, function (row) max(row) < 0), ]
    
    # add back to original dataset
    temp_dt <- rbind(temp_dt_remainder, temp_dt_main)

    # return
    return (temp_dt)
}

### Master function ################################################################################################################
## define function: convert to wide format --> rownames = uniprot IDs,
data_preformatter_wide <- function (input_list, outputID, writefile = NULL, outdir, verbose = F,
                                    prenormalisation_logbase = 2, show_postlog_intensity_distribution = F,
                                    peptide_length_min = 6, peptide_length_max = 25, unique_peptides_min = 2,
                                    protein_choice, intensity_calc_method, imputation_mode = "QRILC") {
    # concatenate MaxQuant evidence.txt files and convert to tsv format  
    temp_input <- data.table()
    if (length(grep("mq-evi", outputID)) > 0) { # if starting from evidence.txt
        temp_input <- evi_to_combined_tsv(input_list = input_list, outputID = outputID, 
                                          writefile = writefile, verbose = verbose,
                                          unique_peptides_min = unique_peptides_min,
                                          peptide_length_min = peptide_length_min,
                                          peptide_length_max = peptide_length_max,
                                          intensity_calc_method = intensity_calc_method)
    } else if (length(grep("mq-pg", outputID)) > 0) { # if starting from proteinGroups
        temp_input <- pg_to_combined_tsv(input_list = input_list, outputID = outputID, 
                                         writefile = writefile, verbose = verbose,
                                         unique_peptides_min = unique_peptides_min,
                                         protein_choice = protein_choice) 
    } else stop ("Error in `data_preformatter_wide()`: input lis file type isn't tagged as 'mq-evi' or 'mq-pg'.")
   
    # define temp_dt
    temp_output <- as.data.table(sort(unique(temp_input$protein_main))) # reformatting, as this returns a list; get protein names list
    colnames(temp_output) <- "protein_main"

    # loop through unique master experiment groups  
    for (exp in unique(temp_input$experiment_master)) {
      	# # toy data
      	# exp <- "89FAIMS"
      	cat("\n",rep("-", 42), "\nStarting transformation of dataset ", outputID, " using experiment group ", exp, " and ",
      	    intensity_calc_method, " as an intensity calculation method.\nTransforming data into wide format...", sep = "")
    	 
      	# create experimental subset based on master experiment
      	temp_subset <- temp_input[experiment_master == exp][ # subset by experiment
         	, .(intensity, protein_main, experiment)] # keep intensities, uniprot IDs, and experiment labels
        
      	# as.numeric transform: if not done, dcast will freak out and spew out junk;
        	# log transform: necessary before normalisation and imputation; done now due to simplicity vs wide format
      	temp_subset[, intensity := log(as.numeric(intensity), base = prenormalisation_logbase)]
     	
      	# transform into wide format
      	temp_subset <- dcast.data.table(temp_subset, protein_main ~ experiment, value.var = "intensity")
    	 
      	# Create a histogram for each cell type to view log2'd intensity variation
      	if (show_postlog_intensity_distribution) {
        	for (sample in colnames(temp_subset[, -c("protein_main")])) {
          	hist(temp_subset[, get(sample)], breaks = 81,
               	xlab = "log2(intensity)", main = paste("Log2 intensity distribution for", sample))
        	}
      	}
     	 
      	# LoessF normalisation with limma; 3 iterations
      	temp_subset[, 2:ncol(temp_subset)] <- temp_subset[, 2:ncol(temp_subset)] %>%
        	as.matrix() %>% # normalizeCyclicLoess requires a matrix
        	normalizeCyclicLoess(x = ., iterations = 3, method = "fast") %>%
        	as.data.table
     	 
      	# perform selected imputation
      	temp_subset <- intensity_imputer(input = temp_subset, imputation_mode = imputation_mode)
     
      	# discount IgG values if present
      	if (length(grep(x = colnames (temp_subset), pattern = "IgG")) == 0) temp_subset <- subtract_IgG(input = temp_subset)
     	
      	# merge with temp_dt
      	temp_output <- merge.data.table(temp_output, temp_subset, bymq_pg_list_99 = "protein_main", all = TRUE)
      	cat("\nDone!\n\n", sep = "")
    }

  	# last round of cleaning: remove NA-only rows and contaminants
  	sample_cols <- colnames(temp_output) %>% 
  	    .[. != "protein_main"]
  	temp_output <- temp_output[!grepl("^CON_", temp_output$protein_main), , drop = FALSE] %>% # drom contaminants
  	    .[!rowSums(is.na(.[, ..sample_cols])) == length(sample_cols)] # drop NA-only rows
  	
    # write temp_dt
    if (!is.null(writefile)) {
        fwrite(x = temp_output, sep = "\t", file = paste0(outdir, paste("wide", outputID, session_name, ".tsv")))
    }
  	
  	# return output
  	return (temp_output)
}
                                           

### Run pipeline(s) - PLK89 ----------------------------------------------------------------------------------------------------------------
# init output list
wide_list <- list()

# preformat data from proteinGroups.txt inputs; init output list
data_wide_pg <- data_preformatter_wide(input_list = mq_pg_list_89,
                                       outputID = attr(mq_pg_list_89, "filetype"), 
                                       writefile = T, outdir = out_wide_pg,
                                       prenormalisation_logbase = prenormalisation_logbase,
                                       unique_peptides_min = unique_peptides_min,
                                       protein_choice = protein_choice,
                                       imputation_mode = imputation_mode, 
                                       intensity_calc_method = "MaxLFQ") %>%
    setattr(name = "description", value = paste(attr(mq_pg_list_89, "filetype"), "MaxLFQ", sep = "-"))

wide_list[[1]] <- data_wide_pg

# preformat data from evidence.txt inputs based on multiple protein-level intensity-generation methods
counter <- 2 # setup counter for output insertion into lists
for (method in c("sum", "average", "median")) {
    data_wide_evi <- data_preformatter_wide(input_list = mq_evi_list_89,
                                            outputID = attr(mq_evi_list_89, "filetype"), 
                                            writefile = T, outdir = out_wide_evi,
                                            prenormalisation_logbase = prenormalisation_logbase,
                                            peptide_length_min = peptide_length_min,
                                            peptide_length_max = peptide_length_max,
                                            unique_peptides_min = unique_peptides_min,
                                            protein_choice = protein_choice,
                                            imputation_mode = imputation_mode, 
                                            intensity_calc_method = method) %>%
        setattr(name = "description", value = paste(attr(mq_evi_list_89, "filetype"), method, sep = "-"))
        
    # add output into list and iterate counter
    wide_list[[counter]] <- data_wide_evi
    counter <- counter + 1
}

### Run pipeline(s) - PLK99 ----------------------------------------------------------------------------------------------------------------
# init output list
wide_list <- list()

# preformat data from proteinGroups.txt inputs; init output list
data_wide_pg <- data_preformatter_wide(input_list = mq_pg_list_99,
                                       outputID = attr(mq_pg_list_99, "filetype"), 
                                       writefile = T, outdir = out_wide_pg,
                                       prenormalisation_logbase = prenormalisation_logbase,
                                       unique_peptides_min = 3,
                                       protein_choice = protein_choice,
                                       imputation_mode = "Razor", 
                                       intensity_calc_method = "MaxLFQ") %>%
    setattr(name = "description", value = paste(attr(mq_pg_list_99, "filetype"), "MaxLFQ", sep = "-"))

wide_list[[1]] <- data_wide_pg

# preformat data from evidence.txt inputs based on multiple protein-level intensity-generation methods
counter <- 2 # setup counter for output insertion into lists
for (method in c("sum", "average", "median")) {
    data_wide_evi <- data_preformatter_wide(input_list = mq_evi_list_89,
                                            outputID = attr(mq_evi_list_89, "filetype"), 
                                            writefile = T, outdir = out_wide_evi,
                                            prenormalisation_logbase = prenormalisation_logbase,
                                            peptide_length_min = peptide_length_min,
                                            peptide_length_max = peptide_length_max,
                                            unique_peptides_min = 3,
                                            protein_choice = protein_choice,
                                            imputation_mode = "Razor", 
                                            intensity_calc_method = method) %>%
        setattr(name = "description", value = paste(attr(mq_evi_list_99, "filetype"), method, sep = "-"))
        
    
        
    # add output into list and iterate counter
    wide_list[[counter]] <- data_wide_evi
    counter <- counter + 1
}
```

## 1.2 Plots - diagnostic
Not yet introduced --> kept here in case I need to return back to it

```{r 2_diagnostic_plots, eval = FALSE}
### Setup
## Libraries
library("data.table")
library("conflicted")
library("ggplot2")
library("ggrepel")
library("tidyverse")
# library("pheatmap")

## Directories
outdir <- "~/MS/img/diagnostics/"
indir <- "~/MS/analysis/evi_wide/"
if(dir.exists(outdir) == FALSE) dir.create(outdir, showWarnings = FALSE)

## load files
mq_og <- fread("~/MS/analysis/evi_wide/old/evi_MaxQuant_pre.tsv", sep = "\t")
evi_list <- list(fread(paste0(indir, paste("wide_MaxQuant_2-unique-peptides_log2_intensCalc-sum_impute-QRILC.tsv", sep = "\t"))) %>%
               	.[,protein_main := NULL],
             	fread(paste0(indir, paste("wide_MaxQuant_2-unique-peptides_log2_intensCalc-average_impute-QRILC.tsv", sep = "\t"))) %>%
               	.[,protein_main := NULL],
             	fread(paste0(indir, paste("wide_MaxQuant_2-unique-peptides_log2_intensCalc-median_impute-QRILC.tsv", sep = "\t"))) %>%
               	.[,protein_main := NULL])

## define normalisation plotter
normalisation_ggplotter <- function (input, gather = FALSE, maintitle, xtitle, ytitle, writefile = NULL, filename) {
  temp_plot <- ggplot(data = (if (gather) gather(input, key = "Column", value = "Value") else input),
                  	if (gather) aes(x = Column, y = Value, fill = Column) else aes(x = experiment, y = log10(intensity), fill = experiment)) +
	geom_violin() +
	geom_boxplot(width=0.1, outlier.shape = NA) + # adds boxplot into violin plot centre to add quantiles and median
	labs(title = maintitle, x = xtitle, y = ytitle) +
	theme(legend.position = "none", plot.title = element_text(hjust = 0.5, size = 10),
      	axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
 
  # save if specified
  if (!is.null(writefile)) ggsave(filename = paste0(writefile, filename), temp_plot, scale = 1)
 
  # return
  return (temp_plot)
}

### Plots
## Boxplot: intensities
# pre-normalisation MaxQuant
normalisation_ggplotter(input = mq_og, xtitle = "Experiment ID", ytitle = "log10(Intensity)",
                    	maintitle = "Log10 intensity boxplots for MaxQuant data (raw)")#,
                    	#writefile = outdir, filename = "MaxQuant_boxplot_intensities_raw.png")

# quantile-normalisation with imputation MaxQuant
for (id in 1:3) {
  ## toy data
  #id <- 1
  intensity_calculation_mode <- list("sum", "average", "median")[[id]]
  temp_plot <- normalisation_ggplotter(input = evi_list[[id]], gather = TRUE, xtitle = "Experiment ID",
                      	ytitle = paste0("log2(Intensity (", intensity_calculation_mode,"), imputed)"),
                      	maintitle = paste0("Log2 intensity (", intensity_calculation_mode,
                                         	") boxplots for MaxQuant data (LOESSF-normalised, imputed)"))#,
                    	#writefile = outdir, filename = "MaxQuant_boxplot_intensities_norm_imp.png")
  print(temp_plot)
}



### PCA
## define PCA plotter
pca_plotter <- function (input, outputID, maintitle, writefile = NULL) {
  # # toy data
  # input <- evi_mq
  # outputID <- "MaxQuant"
  # writefile <- TRUE

  # calculate PCAs
  temp_pca <- setnafill(input, fill=0) %>%
	t() %>%
	prcomp(x = ., center = TRUE, scale. = FALSE) %>%
	.$x %>% # have to split, can't combine with as.data.frame() bc error
	as.data.frame()

  # throw error if there aren't at least 2 PCAs, i.e. more than 2 columns
  tryCatch({
	# check if 2 or less PCAs present; discount a column to account for Group
	if (ncol(temp_pca) < 2) stop()
    
	# define group
	temp_pca$Group <- sapply(as.character(row.names(temp_pca)),
                      	function(x) strsplit(x, "_")[[1]][[1]])
    
	# check if there are any rows after removing NA values
	if (nrow(temp_pca) == 0) {
  	message("All rows have NA values after removing them. Unable to perform PCA.")
  	return(NULL)
	}
    
	# prep plot
	temp_plot <- ggplot(temp_pca, aes(x = PC1, y = PC2, colour = Group)) +
  	geom_point(shape=19, size=4, alpha = 0.7)+
  	geom_hline(yintercept = 0, colour = "gray65") +
  	geom_vline(xintercept = 0, colour = "gray65") +
  	labs(x = "PC1", y = "PC2", color = "Experiment ID",
       	title = maintitle) +
  	geom_text_repel(aes(label = rownames(temp_pca)), size = 3, force = 5) +
  	theme(plot.title = element_text(vjust = 0.5)) +
  	theme_classic()
    
	# save plot if stated
	if (!is.null(writefile)) ggsave(filename = paste0(writefile, outputID,"_scatterplot_PCA.png"), temp_plot, scale = 1)
    
	# return
	return (temp_plot)
  }, error = function(e) message("\nInsufficient number of PCAs in your object (i.e. < 2). Investigate...\nLocation: `pca_plotter`"))
}

### do plots
for (id in 1:3) {
  intensity_calculation_mode <- list("sum", "average", "median")[[id]]
  temp_plot <- pca_plotter(input = evi_list[[id]], outputID = "Maxquant",
          	maintitle = paste0("PCA of MaxQuant peptide intensities (", intensity_calculation_mode,")"))#,
                    	#writefile = outdir, filename = "MaxQuant_boxplot_intensities_norm_imp.png")
  print(temp_plot)
}

### clustering (dendrogram)
# ToDo

### heatmap
# ToDo
rm(list = ls(all.names = TRUE))
```

## 1.3 P values calculations and abundance visualisation

**Test choice for abundance comparison**: Two choices are possible for testing fold-change: a Welch T-test with Benjamini-Hochberg FC threshold-based correction, or ROTS. ROTS is recommended ([Comparison](https://towardsdatascience.com/embrace-r-to-boost-your-proteomic-analysis-ea6fdc8909e7), [reason 1](https://doi.org/10.1093/bib/bbw095), [reason 2](https://www.doi.org/10.1371/journal.pcbi.1005562)).

```{r 3_setup_volcano_prepper, warning=FALSE}
### Definitions
## Define xml extractor for uniprot info adder
extract_xml <- function(url, progress_tracker = NULL) {
    # # toy data
    # url <- "https://rest.uniprot.org/uniprotkb/A0A2R8Y4L2.xml"
    # url <- url_list[1]
    
    # setup html retries tracker
    attempt_count <- 0
    temp_xml <- NULL
    
    # attempt to read xml tables 300x before giving up; keep a 0.1-second retry interval
    while (is.null(temp_xml)) {
        attempt_count <- attempt_count + 1
        
        temp_xml <- tryCatch ({
            xml2::read_xml(url(url)) %>%
                xml_ns_strip()
            }, error = function(e) {
        	    if (inherits(e, "try-error")) warning(paste("\nConnection error: ", e$message,"\nLocation: xml_extractor()"))
        	    else stop(e)
        	})
            
    	Sys.sleep(0.1) # wait before retry
	}
  	
  	# read in organism names; return NULL if not human
  	organism_name_latin <- temp_xml %>%
    	xml_find_first(".//name[@type='scientific']") %>%
    	xml_text(trim = TRUE)
    organism_name_common <- temp_xml %>%
  	    xml_find_first(".//name[@type='common']") %>%
    	xml_text(trim = TRUE)
  	if (!(organism_name_latin %in% c("Homo", "Homo sapiens", "H. sapiens")) | 
  	    !(organism_name_common %in% c("Human", "human"))) return (NULL)
  	
  	# read in protein name
  	full_name <- temp_xml %>%
    	xml_find_first(".//fullName") %>%
    	xml_text(trim = TRUE)
 	 
    # read in gene
  	gene_name <- temp_xml %>%
    	xml_find_first(".//name[@type='primary']") %>%
    	xml_text(trim = TRUE)
  	
  	# read in description  (note - will not always be present)
  	description <- temp_xml %>%
    	xml_find_all(".//gene/comment[@type='function']") %>%
    	xml_text(trim = TRUE) 
 	 
  	# if gene description is empty, try to read in the protein description
  	if (length(description) == 0) description <- temp_xml %>%
    	xml_find_all(".//comment[@type='function']") %>%
    	xml_text(trim = TRUE)
  	
  	# read in UniProt subcellular location
  	subcellular_location <- temp_xml %>%
    	xml_find_all(".//comment[@type='subcellular location']") %>%
    	xml_text(trim = TRUE) %>%
  	    gsub("(?<=[a-z])([A-Z])", ";\\1", ., perl = T) # place semicolon b4 each U/C char (!1st) superseded by l/c chars
  	
  	# read in GO data
  	go_data <- temp_xml %>%
    	xml_find_all(".//dbReference[@type='GO']") %>%
  	    xml_find_all(".//property[@type='term']") %>%
  	    xml2::xml_attr("value")
  	
  	# if gene description is still empty, try to read in the GO molecular function
  	if (length(description) == 0) description <- go_data %>% 
  	    .[grepl(pattern = "F:", x = .)] %>%
  	    paste(collapse = ";") %>% 
  	    gsub("F:([a-z])", "\\U\\1", ., perl = TRUE)
  	
  	# if subcellular_location is empty, try to read in the GO version
  	if (length(subcellular_location) == 0) subcellular_location <- go_data %>%
  	    .[grepl(pattern = "C:", x = .)] %>%
  	    paste(collapse = ";") %>% 
  	    gsub("C:([a-z])", "\\U\\1", ., perl = TRUE)
  	
  	# make format nicer if missing values; concatenate if multiple
  	if (length(gene_name) == 0) gene_name <- NA else if (length(gene_name) > 1) gene_name <- paste(gene_name, collapse = "; ")
  	if (length(full_name) == 0) full_name <- NA else if (length(full_name) > 1) full_name <- paste(full_name, collapse = "; ")
  	if (length(description) == 0) description <- NA else if (length(description) > 1) description <- paste(description, collapse = " ")
 	if (length(subcellular_location) == 0) subcellular_location <- NA else if (length(subcellular_location) > 1) subcellular_location <- paste(subcellular_location, collapse = "; ")
  	
  	# add progress tick
  	if (!is.null(progress_tracker)) progress_tracker()
  	 
    # return
    return(list(gene = gene_name, protein_name = full_name, protein_function = description, subcellular_location = subcellular_location))
}

## Define add_uniprot_info -> from uniprot
add_uniprot_info <- function(input, uniprot_ids = "protein_main", cpus = 8) {
    # # toy data
    # input <- temp_dt[p.value_text != "Non-significant" & !is.na(p.value_text)]
    # uniprot_ids = "protein_main"
   
    # init empty data table to store output
    temp_dt <- data.table(ID = unique(input[[uniprot_ids]]),
                          gene = "", protein_name = "", protein_function = "", subcellular_location = "")
    
    
    # get url list
    url_list <- NULL
    for(i in 1:nrow(temp_dt)) {
        # # toy data
        # i <- 1
        url_list <- c(url_list, paste0("https://rest.uniprot.org/uniprotkb/", temp_dt$ID[i], ".xml"))
    }
    
    # scrape using future_map; initiate and reset multithreading plan
    plan(multisession, workers = cpus)
    temp_results <- NULL
    with_progress({
      p <- progressor(steps = length(url_list))
      
      temp_results <- future_map(url_list, extract_xml, progress_tracker = p)
    })
    plan("default")
    
    # load results into temp_dt
    temp_dt[, `:=`(gene = sapply(temp_results, "[[", "gene"),
              protein_name = sapply(temp_results, "[[", "protein_name"),
              protein_function = sapply(temp_results, "[[", "protein_function"),
              subcellular_location = sapply(temp_results, "[[", "subcellular_location"))]

    # Return the resulting data frame
    return(temp_dt)
}

## Define volcano_preformatter; NOTE!!! This assumes a log base of 2 for intensities
volcano_preformatter <- function(input, MS_method, maxP = 0.05, minFC = 1.5, p_test = "ROTS", writefile = NULL, filename = NULL, intensity_logbase = 2, verbose = F, cpus) {
    # # toy data
    # input <- wide_list[[1]]
    # MS_method <- "FAIMS"
    
    if (verbose) cat("Starting volcano_preformatter() for", MS_method, "...")
    
    # extract unique column names (minus protein_main)
    temp_colnames <- unique(gsub("^(\\d{2})(FAIMS)?(_.*)-\\d{1,2}", "\\1\\2\\3", names(input)[-1]))
 
    # setup "static" column descriptors
    pids <- grep(x = colnames(input), pattern = "protein", value = TRUE) # ID of column with protein IDs
    
    # setup dynamic column descriptors
    is_faims <- MS_method == "FAIMS" # bool to check whether the current combination is FAIMS or not
    overlap_info <- grep(x = colnames(input), pattern = paste(ifelse(is_faims, "overlap_info_FAIMS", "overlap_info_classic")), value = TRUE)
    control <- grep(x = colnames(input), pattern = paste0("^89", MS_method, "_C-\\d{1,2}$"), value = TRUE)
    treatment <- grep(x = colnames(input), pattern = paste0("^89", MS_method, "_T-\\d{1,2}$"), value = TRUE)
    baseline <- grep(x = colnames(input), pattern = paste0("^89", MS_method, "_IgG"), value = TRUE)
    baseline_duplicate <- paste0("89", MS_method,"_IgG-", as.numeric(gsub(paste0("89", MS_method,"_IgG-"), "", baseline)) + 1)
    baselines <- c(baseline, baseline_duplicate) # append duplicate baseline cols into 1 object
    
    # subset based on descriptors
    temp_dt <- input[, c(pids, control, treatment, overlap_info, baseline), with = FALSE] %>%
        .[rowSums(!is.na(.[, c(control, treatment), with = FALSE])) != 0, ] %>% # remove NA-only rows
        .[, eval(baseline_duplicate) := .[,..baseline]]
    
    # calculate overlap fold change
    for (i in 1:3) {
        abundance_pair <- list(list(control, treatment),
                               list(control, baselines),
                               list(treatment, baselines))[[i]]
        overlap_text <- list("overlap", "EC", "Cyt")[[i]]
        maingroup <- abundance_pair[[2]] # treatment or baselines
        subgroup <- abundance_pair[[1]] # control or treatment
        temp_dt[get(overlap_info) == overlap_text, paste0("log", intensity_logbase, "_FC") :=
            rowMeans(.SD[, ..maingroup]) - rowMeans(.SD[, ..subgroup]), .SDcols = c(maingroup,subgroup)]
    }

    # load new FC column into variable
    FC_col <- grep(pattern = "log\\d{1,2}_FC", x = colnames(temp_dt), value = T)
    
    # preform p-value calculation
    if (verbose) cat(paste0("\nPerforming p-value calculation (", p_test, ")."))
    if (p_test == "ROTS") {
    	for (i in 1:3) {
    	    # # toy data
    	    # i <- 3
    	    abundance_pair <- list(list(control, treatment),
                                   list(control, baselines),
                                   list(treatment, baselines))[[i]]
            overlap_text <- list("overlap", "EC", "Cyt")[[i]]
            maingroup <- abundance_pair[[2]] # treatment or baselines
            subgroup <- abundance_pair[[1]] # control or treatment
            
            # does the given subset even exist? If not, skip
            if (!(overlap_text %in% unique(unlist(temp_dt[,..overlap_info])))) next
            
            # select groups for ROTS
    	    groups <- c(rep(0, length(subgroup)), rep(1, length(maingroup)))

    	    # convert temp_dt to data frame with rownames
        	temp_ROTS <- as.data.frame(temp_dt[get(overlap_info) == overlap_text, c(subgroup, maingroup), with = FALSE])
        	row.names(temp_ROTS) <- temp_dt[get(overlap_info) == overlap_text]$protein_main
            
            # run ROTS if the number of unique values is larger than 1 in the 1st replicate (temporary solution for aberrant proteinGroups output with multiple proteins from the same group listed as different ones even though they have the exact same intensity values)
            if (length(unique(temp_ROTS[,1])) > 1) {
                temp_ROTS <- as.matrix(temp_ROTS) %>%
            	    ROTS(data = ., groups = groups, B = 2*nrow(temp_ROTS), progress = verbose, seed = 1234, 
            	         log = as.logical(intensity_logbase > 1), verbose = verbose)
            } else {
                if (verbose) cat("\nWarning! The current overlap (", overlap_text, ", pairing: ", paste0(unlist(abundance_pair), collapse = ", "),
                                 ") contains only non-unique values in columns. Switching from ROTS to a F-test-defined T-test.\n")
                temp_ROTS$pvalue <- apply(temp_ROTS, 1, function(x) {
                    tryCatch({
                        # first, do F-test, then do T-test with the appropriate type
                        try_result <- t.test(x[subgroup], x[maingroup], var.equal = var.test(x[subgroup], x[maingroup])$p.value > 0.05)$p.value
                        return (try_result)
                    }, error =  function(cond) {
                        message(paste0("\nTryCatch error in t.test.default(x[subgroup], x[maingroup], var.equal = T) :\n  data are essentially constant. \nP-values set to 0.001234512341231217."))
                        message(paste0("Original error message: ", cond))
                        # Return pval of 0; this will indicate an error if looked at in the future.
                        return (0.001234512341231217)
                        })
                    })
    
                temp_ROTS$FDR <- NA
            }
        	
    	    if (verbose) cat("\nROTS outputs for ROTS FDR = 0.01:\n", summary(temp_ROTS, fdr = p_test_FDR_cutoff))
        
    	    # append to temp_dt
    	    temp_dt[get(overlap_info) == overlap_text, `:=` (p.value=temp_ROTS$pvalue, ROTS_FDR=temp_ROTS$FDR)] # append ROTS outputs
        }
    } else if (p_test == "t-test") {
    	for (i in 1:3) {
            # # toy data
    	    # i <- 1
    	    abundance_pair<- list(list(control, treatment),
                                  list(control, baselines),
                                  list(treatment, baselines))[[i]]
            overlap_text <- list("overlap", "EC", "Cyt")[[i]]
            maingroup <- abundance_pair[[2]] # treatment or baselines
            subgroup <- abundance_pair[[1]] # control or treatment
            
            # does the given subset even exist? If not, skip
            if (!(overlap_text %in% unique(unlist(temp_dt[,..overlap_info])))) next
            
            # select groups for t-test
    	    groups <- c(rep(0, length(subgroup)), rep(1, length(maingroup)))
    	    
    	    # perform F-test, and based on skedasticity, do Welch T-test or Student's T-test
    	    temp_dt[get(overlap_info) == overlap_text, 
    	            T_test := apply(temp_dt[get(overlap_info) == overlap_text, .SD, .SDcols = c(subgroup, maingroup)], 1, 
    	                            function (x) {t.test(x[subgroup], x[maingroup],
    	                                                 var.equal = var.test(x[subgroup], x[maingroup])$p.value > 0.05 # F-test; if > 0.05, Welch, else students' t-test
    	                                                 )$p.value})]
        	
    	    # cut off data based on pre-selected FC (i.e. smaller data); perform Benjamini-Hochberg correction
        	temp_pvals <- temp_dt[abs(get(FC_col)) >= minFC & get(overlap_info) == overlap_text, T_test] %>%
        	    p.adjust(., method = "BH")
            
        	# prepare cosmetic p.values to be able to show a nice-ish volcano plot - these don't mean anything, but they make the plot work (kinda) while ensuring that the actual Benjamini-Hochber correction remains valid
        	temp_pvals_cosmetic <- temp_dt[abs(get(FC_col)) < minFC & get(overlap_info) == overlap_text, T_test] %>%
        	    p.adjust(., method = "BH")
            
        	# append to OG temp_dt
        	temp_dt[abs(get(FC_col)) >= minFC & get(overlap_info) == overlap_text, p.value := temp_pvals]
        	temp_dt[abs(get(FC_col)) < minFC & get(overlap_info) == overlap_text, p.value := temp_pvals_cosmetic]
    	}
    } else stop ("\nNo p-value test selected, select a test from the following: t-test, ROTS.\nLocation: `volcano_prefomatter()`.")

    # add categorising column for easier visualisation
    if (verbose) cat("\nFormatting for volcano plot...")
    temp_dt$p.value_text <- vector("character", nrow(temp_dt)) # kept so that EC/Cyt without IgG values are still web scraped for info
    for (i in 1:3) {
        # # toy data
        # i <- 3
        abundance_pair <- list(list(control, treatment),
                               list(control, baselines),
                               list(treatment, baselines))[[i]]
        overlap_text <- list("overlap", "EC", "Cyt")[[i]]
        maingroup <- str_extract(string = abundance_pair[[2]][1], pattern = "^(.*)-\\d{1}$", group = 1) 
        subgroup <- str_extract(string = abundance_pair[[1]][1], pattern = "^(.*)-\\d{1}$", group = 1)

        for (j in 1:nrow(temp_dt[get(overlap_info) == overlap_text, ])) {
    	    # j <- 1
            if (j == 0) next
            if (is.na(temp_dt[get(overlap_info) == overlap_text,][j, "p.value"])) { # fill with NA if p-value not calculated and skip the rest of the operation
    	        temp_dt[get(overlap_info) == overlap_text,][j, "p.value_text"] <- NA
    	        next
    	    } 
                 
            if (temp_dt[get(overlap_info) == overlap_text,][j, "p.value"] <= maxP &
                       temp_dt[get(overlap_info) == overlap_text,][j, get(FC_col)] >= log(minFC, intensity_logbase)) {
                temp_dt[get(overlap_info) == overlap_text,][j, "p.value_text"] <- paste("Up in", maingroup)
    	    } else if (temp_dt[get(overlap_info) == overlap_text,][j, "p.value"] <= maxP & 
    	               temp_dt[get(overlap_info) == overlap_text,][j, get(FC_col)] <= -1 * log(minFC, intensity_logbase)) {
    	        temp_dt[get(overlap_info) == overlap_text,][j, "p.value_text"] <- paste("Up in", subgroup)
    	    } else temp_dt[get(overlap_info) == overlap_text,][j, "p.value_text"] <- "Non-significant"
    	    
    	    if (temp_dt[get(overlap_info) == overlap_text,][j, "p.value"] == 0.001234512341231217) {
                    temp_dt[get(overlap_info) == overlap_text,][j, "p.value_text"] <- paste("Duplicated; failed t-test")
            } 
    	    
    	    if (round(temp_dt[get(overlap_info) == overlap_text,][j, "p.value"], 8) == 0.04811448) {
                    temp_dt[get(overlap_info) == overlap_text,][j, "p.value_text"] <- paste("Duplicated")
            }
        }
    }

    # check if there are any significant adjusted p-values in the first place
    if (nrow(temp_dt[p.value_text != "Non-significant"]) == 0) cat(paste0("Warning, there are no significant p-values for the given pairs in the dataset provided. You may wish to re-avaluate your experimental design, that is if you have a proper number of replicates to do good statistics in the first place. Two is not a sufficient number in this scenario.\nLocation: volcano_preformatter()\n"))
    
    # add uniprot IDs and descriptions to significant proteins
    if (verbose) cat("\nAppending uniprot information...")
    temp_dt <- merge.data.table(x = temp_dt, by.x = "protein_main", all.x = TRUE, by.y = "ID",
                                y = add_uniprot_info(temp_dt[p.value_text != "Non-significant" & !is.na(p.value_text)], cpus = cpus))

    # write if specified
    if (!is.null(writefile)) {
	    if (verbose) cat("\nWriting file...")
	    fwrite(x = temp_dt, file = paste0(writefile, filename, ".tsv"), sep = "\t")
    }
 
    # return the modified data table
    return (temp_dt)
}


### volcano plotter function
volcano_plotter <- function(input, pairing_info, maxP = 0.05, minFC = 1.5, writefile = NULL, filename, plotly = F, intensity_logbase = 2, method, target_proteins_list = NULL) {
    # # toy data
    # input <- temp_abundance
    # input <- abundances_list[[1]]
    
    # pairing_info <- "Cyt_FAIMS" 
    # writefile <- outdir_img
    # filename <- "evi_MaxQuant_89_C_T_imputation_log2FC_ROTS_volcano.png"
    # maxP <- 0.05
    # plotly <- TRUE
    # minFC <- 1.3
    # method <- "sum"
    
    # Pass if input is NULL
    if (is.null(input)) stop (paste0("\nThe input is NULL, make sure that it's defined.\nLocation: `volcano_plotter()`."))
    
    # load FC column into variable (adaptable)
    FC_col <- grep(pattern = "log\\d{1,2}_FC", x = colnames(input), value = T)
 
    # get subset where overlap_info = overlap_text
    overlap_info <- ifelse(test = length(grep(x = pairing_info, pattern = "FAIMS")) > 0, 
                           yes = "overlap_info_FAIMS", no = "overlap_info_classic")
    overlap_text <- str_extract(string = pairing_info, pattern = "^(\\w+)_\\w*$", group = 1)
    temp_subset <- input[get(overlap_info) == overlap_text]
    
    # if empty, return text
    if (nrow(temp_subset) == 0) return (paste0("There are no elements in the plot."))
    
    # define pairing based on overlap_text
    functional_columns <- grep(x = names(temp_subset), pattern = "\\d{2}\\w*_\\w{1,3}-\\d{1}", value = T) # grab intensity cols
    functional_columns <- functional_columns[colSums(is.na(temp_subset[, ..functional_columns])) == 0] %>% # filter out those with NAs
        str_split(., "-", simplify = T) %>% # split colnames
        .[, 1] %>% # grab basename
        unique() # reduce to pair
    
    # plot the output
    temp_plot <- ggplot(temp_subset, aes(colour = p.value_text, x = get(FC_col), y = -log10(p.value))) +
        geom_point(shape=19, size=2, alpha = 0.6,
                   if(plotly) aes(text = paste0("\nProtein name: ", protein_main, "\nGene ID: ",
                                                gene, "\nProtein name: ", protein_name))) +
        geom_hline(yintercept = -1*log10(maxP), colour = "gray65") +
        # geom_vline(xintercept = 0, colour = "black") + # centre
        geom_vline(xintercept = log(minFC, intensity_logbase), colour = "gray65") +
        geom_vline(xintercept = -1*log(minFC, intensity_logbase), colour = "gray65") +
        ggtitle(paste0("Volcano plot of ", functional_columns[1], " vs ", functional_columns[2],
                       " (pval <= ", maxP, ", ", paste0(FC_col)," >= ", minFC, ")",
                       "\nMS methodology: ", ifelse(test = length(grep(x = pairing_info, pattern = "FAIMS")) > 0,
                                                    yes = "LC-FAIMS-MS/MS", no = "LC-MS/MS"),
                       "\nIntensity calculation method: ", method)) +
        theme_classic() +
        theme(legend.title = element_blank(), legend.text = element_text(size=12),
              plot.title = element_text(size=10)) +
        labs(x = paste0(paste0(FC_col),"(", functional_columns[1], " vs ", functional_columns[2], ")"), y = paste0("-log10(p-value)"),
             colour = "Upregulation")

	# define a static non-plotly plot with geom_text_repel
	static_plot <- temp_plot +
	    geom_text_repel(data = subset(temp_subset, p.value != "Non-significant" & p.value != ""),
	                    aes(get(FC_col), -log10(p.value), label = gene), max.overlaps = 35)

	# writefile if specified
	if (!is.null(writefile)) {
  	    ggsave(filename = paste0(writefile, filename, ".png"), plot = static_plot, scale = 1)
	}
    
	# return plot
	if (plotly) return (plotly::ggplotly(temp_plot, tooltip = "text"))
	else return (static_plot)
}


### Setup
## Directories
outdir_img <- paste0(out_img, session_name, "/")

if (dir.exists(outdir_img) == FALSE) dir.create(outdir_img, recursive = T)
if (dir.exists(out_volcano_pre) == FALSE) dir.create(out_volcano_pre, recursive = T)

### Does proteinase K treatment change the abundance of any proteins - hp?
# init empty storage lists
abundances_list <- list()
plot_list <- list()
# counter_if_not_generating_abundances <- 1

# prep plots
for (input in wide_list) {
    for (MS_method in c("", "FAIMS")) { # "" =  classic;
        # # toy data
        # input <- wide_list[[1]]
        # MS_method <- ""

        # generate filename and its components
        fn_description <- ifelse(test = MS_method == "FAIMS",
                                 yes = fn_description <- paste0(str_replace(string = attr(input, "description"), pattern = "[-][^-]+$", replacement = ""), "FAIMS"),
                                 no = str_replace(string = attr(input, "description"), pattern = "[-][^-]+$", replacement = ""))
        fn_ICM <- str_split(string = attr(input, "description"), pattern = "-")[[1]][4] # intensity calc method
        fn_description_ICM <- paste0(fn_description, "-", fn_ICM)
        filename <- paste0(paste("abundance", fn_description, session_name, sep = "_"), ".tsv")
        
        # calculate abundances
        cat("\nCalculating: ", filename)
        temp_abundance <- volcano_preformatter(input = input, MS_method = MS_method, verbose = F,
                                               maxP = maxP, minFC = minFC,
                                               p_test = "ROTS",
                                               writefile = out_volcano_pre, filename = filename,
                                               intensity_logbase = prenormalisation_logbase, cpus = cpus) %>%
            setattr(name = "description", value = fn_description_ICM)  # attribute intensity calculation method (ICM) used

        # add to abundance list
        abundances_list[[fn_description_ICM]] <- temp_abundance
        
        # generate plots
        for (overlap in c("overlap", "EC", "Cyt")) {
            # # toy data
            # overlap <- "overlap"
            # MS_method <- ""
            
            fn_description_ICM_overlap <- paste(fn_description_ICM, overlap, sep = "-")
            filename <- paste0(paste("abundance", fn_description_ICM_overlap, session_name, sep = "_"), ".tsv")

            # prep plot and show it
            cat ("\nPlotting: ", filename)
            temp_plot <- volcano_plotter(input = temp_abundance,#abundances_list[[counter_if_not_generating_abundances]],
                                         pairing_info = paste(overlap, MS_method, sep = "_"),
                                         writefile = outdir_img,
                                         filename = filename, plotly = F,
                                         method = fn_ICM)

            # add passing p values into abundances list, update plot list, and iterate counter
            plot_list[[fn_description_ICM_overlap]] <- temp_plot
        }
        # counter_if_not_generating_abundances <- counter_if_not_generating_abundances + 1
    } 
}
if (!exists("testing")) beepr::beep(1)
```


# 2. Results: volcano plots and tables {.tabset .tabset-fade .tabset-pills}

## 2.1 Information

### 2.1.1 Experiment recap

**Recap - PLK89**: This sample (PLK89) is from an anti-protein_of_interest IP of an H1299 nuclear extract, where 89_C is a control and 89_T is treated with proteinase K 30 mins before extraction.
There were 2 technical replicates of each sample, with a single IgG control.

The anti-protein_of_interest antibody targets the relatively unstructured 42-amino acid cytoplasmic domain of protein_of_interest, as well as potentially some of its C-terminal transmembrane domain. While the later is unlikely due to protein trafficking mechanics, where it is pretty difficult to remove a membrane from the transmembrane region of a protein when it's endocytosed, I still mention it just to be sure.

### 2.1.2 LC-MS/MS vs FAIMS-based MS

**LC-MS/MS**

1.  Liquid chromatography (LC): The prepared sample is injected into a liquid chromatography system, where it undergoes separation based on its chemical properties. Typically, a chromatographic column is used to separate the analytes.
2.  Ionization: The sample is ionized using techniques like electrospray ionization (ESI) or matrix-assisted laser desorption/ionization (MALDI), producing ions in the gas phase.
3.  Mass analysis: The ions generated in step 2 are introduced into an Orbitrap Exploris 480 mass analyzer. The mass analyzer separates the ions based on their m/z and measures their intensities.
4.  Tandem MS (MS/MS): In LC-MS/MS, an additional step called tandem MS is performed. Selected ions from the mass analyzer are fragmented using collision-induced dissociation (CID) or other fragmentation methods. The resulting fragments are then analyzed by a second mass analyzer, providing information about the structural characteristics of the analytes.

**FAIMS-based MS**

1.  Liquid chromatography (LC): The prepared sample is injected into a liquid chromatography system, where it undergoes separation based on its chemical properties.
Typically, a chromatographic column is used to separate the analytes.
2.  Ionization: The sample is ionized using techniques like electrospray ionization (ESI) or matrix-assisted laser desorption/ionization (MALDI), producing ions in the gas phase.
3.  *FAIMS separation: The resulting ions are introduced into the FAIMS device, where a high-frequency asymmetric waveform is applied. The ions undergo cyclical lateral motion in the high-field region, and their separation is based on their differential mobility.*
4.  *FAIMS output: The separated ions exit the FAIMS device and are directed to the mass analyzer for detection and analysis.*
5.  Mass analysis: The ions generated in step 2 are introduced into an Orbitrap Exploris 480 mass analyzer.
The mass analyzer separates the ions based on their m/z and measures their intensities.
6.  Tandem MS (MS/MS): In LC-MS/MS, an additional step called tandem MS is performed.
Selected ions from the mass analyzer are fragmented using collision-induced dissociation (CID) or other fragmentation methods.
The resulting fragments are then analyzed by a second mass analyzer, providing information about the structural characteristics of the analytes.

### 2.1.3 Data analysis

**Data analysis**:

To produce this graph, I went through multiple steps.

**Script 1: MS_2023_pre.RMD** -- Not used: I started out with MaxQuant proteinGroups.txt files.

**Script 2: MS_2023_volcano_MaxQuant_proteinGroups.RMD**

1.  Conversion into wide format:
	1.  Rows with peptides are converted into unique protein IDs for the datasets and columns are individual experiments. Only proteins with at least `r unique_peptides_min` unique peptides are kept.
	2.  Intensities for proteins were generated via MaxQuant's MaxLFQ. To select a single protein from a protein group, only the first (highest number of unique peptides) was kept.
	3.  All intensity values are log2-transformed to change distribution from left-skewed to normal.
	4.  Normalisation (LoessF) was performed between experiment groups (e.g. PLK89, PLK89FAIMS) so that samples can be compared.
	5.  Imputation (QRILC) was performed on all rows. More specifically, rows that had 50% or less total missing values (e.g. Plk89 treated rep1 and Plk89 untreated rep2). Those with more than 50% missing values were dropped.  
	6.  IgG baseline intensities are subtracted from experimental intensities.
2.  Diagnostic plots
	1.  Pre and post quantile normalisation plots. Keep in mind that this is after filtering, so the distributions will likely be skewed.
	2.  PCA plots.
3.  P value calculation and volcano plots
	1.  Groups were selected.
	2.  Log2 fold-change values were generated
	3.  *For T-testing*: an F-test was performed to evaluate skedasticity and perform a subsequent student's (non-significant) or Welch (significant) T-test. A Benjamini-Hochberg p-value adjustment was performed on the selected log2FC threshold subset - this can be used in larger datasets to get more stringent p-values.
    	*For ROTS (default)*: used bootstrapping value of 2*number of proteins in dataset, set seed at "1234".
	5.  UniProt gene and protein names, as well as protein descriptions where appropriate, were added to the data table.
	6.  The resulting fold change and p values were plotted against each other using a volcano plot.

## 2.2 Volcano plots - PLK89 control vs treatment IP abundances

*This shows protein abundances across the control and proteinase K-treated nuclear IP.*
This should show proteins that bind both the control and the treatment IPs, i.e. what can bind to the intracellular domain alone and binds differently when the whole protein is present.

Two different MS methods were used - LC-MS/MS, and LC-FAIMS-MS/MS.
Four different protein-level intensity generation methods were used - MaxLFQ, sum, average, and median.

```{r 4_volcano_overlap, warning=FALSE, message=FALSE}
for (i in 1:(length(plot_list)/3)){
    index <- 3*i - 2
    print(plot_list[[index]])
    #print(names(plot_list[index]))
}
```

## 2.3 Volcano plots - PLK89 control IP vs control baseline abundances

*This shows protein abundances across the control (not proteinase K-treated) nuclear IP and the IgG baseline.*
This effectively shows what the control IP with the whole protein drags up compared to just the IgG baseline. This should therefore show proteins that don't bind to the treatment at all, meaning that the proteins listed should interact with the extracellular domain.

Two different MS methods were used - LC-MS/MS, and LC-FAIMS-MS/MS.
Four different protein-level intensity generation methods were used - MaxLFQ, sum, average, and median.

```{r 5_volcano_EC, warning=FALSE, message=FALSE}
for (i in 1:(length(plot_list)/3)){
    index <- 3*i - 1
    print(plot_list[[index]])
    #print(names(plot_list[index]))
}
```

## 2.4 Volcano plots - PLK89 treatment IP vs control baseline abundances

*This shows protein abundances across the control (not proteinase K-treated) nuclear IP and the IgG baseline.*
This effectively shows what the treatment IP with the whole protein drags up compared to just the IgG baseline. *One major caveat is that this is the IgG baseline wasn't treated with protease K*. This should therefore show proteins that don't bind to the control at all, meaning that the proteins listed should interact with the intracellular domain only, or with the intracellular domain when the extracellular domain is missing.

Two different MS methods were used - LC-MS/MS, and LC-FAIMS-MS/MS.
Four different protein-level intensity generation methods were used - MaxLFQ, sum, average, and median.

```{r 6_volcano_Cyt, warning=FALSE, message=FALSE}
for (i in 1:(length(plot_list)/3)){
    # # toy data
    # i <- 1
    
    index <- 3*i
    
    print(paste0("Dataset: ", names(plot_list[index])))
    print(plot_list[[index]])
    print("~ ~ ~")
}
```
## 2.5 Table - PLK89 control IP unique proteins (not found in treatment or in the baseline)

This effectively shows what the control IP with the whole protein drags up compared to the treatment IP or just the IgG baseline. This should show proteins that don't bind to the treatment at all, meaning that the proteins listed should interact with the extracellular domain only, or with the intracellular domain when the extracellular domain is present only (i.e. not when it's missing).

Two different MS methods were used - LC-MS/MS, and LC-FAIMS-MS/MS.
Four different protein-level intensity generation methods were used - MaxLFQ, sum, average, and median.

```{r 7_table_risky_EC, warning=FALSE, message=FALSE}
temp_table <- list()
for (i in 1:(length(abundances_list))) {
    # # toy data
    # i <- 1
    
    overlap_info <- ifelse(test = i %% 2 == 0, 
                           yes = "overlap_info_FAIMS", no = "overlap_info_classic")
    
    temp_table[[names(abundances_list[i])]] <- abundances_list[[i]][
        p.value_text != "Non-significant" & !is.na(p.value_text)][get(overlap_info) == "risky_EC"]
}

for (dtable in temp_table) {
    cat(paste0("\n\nDataset: ", names(abundances_list[i])), "\n")
    print(dtable)
}

```
## 2.7 Table - PLK89 treatment IP unique proteins (not found in control or in the baseline)

This effectively shows what the treatment IP with the whole protein drags up compared to just the IgG baseline. *One major caveat is that this is the IgG baseline wasn't treated with protease K*. This should therefore show proteins that don't bind to the treatment at all, meaning that the proteins listed should interact with the intracellular domain only, or with the intracellular domain when the extracellular domain is missing.

Two different MS methods were used - LC-MS/MS, and LC-FAIMS-MS/MS.
Four different protein-level intensity generation methods were used - MaxLFQ, sum, average, and median.

```{r 8_table_risky_Cyt, warning=FALSE, message=FALSE}
temp_table <- list()
for (i in 1:(length(abundances_list))) {
    # # toy data
    # i <- 1
    
    overlap_info <- ifelse(test = i %% 2 == 0, 
                           yes = "overlap_info_FAIMS", no = "overlap_info_classic")
    
    temp_table[[names(abundances_list[i])]] <- abundances_list[[i]][
        p.value_text != "Non-significant" & !is.na(p.value_text)][get(overlap_info) == "risky_Cyt"]
}

for (dtable in temp_table) {
    cat(paste0("\n\nDataset: ", names(abundances_list[i])), "\n")
    print(dtable)
}
```


## 2.8 A summary of the intensity overlaps
### 2.8.1 Construct an Excel workbook containing a summary of this data can be found in the folder along with this document.
```{r 9_prep_out_report, warning=FALSE, message=FALSE}
### Information table - variables used and descriptions ---------------------------------------------------------------------------
info_namesCol <- c("Pipeline input", 
                   "Minimum unique peptides per protein", "Minimum peptide length", "Maximum peptide length",
                   "Peptide-level intensity normalisation", 
                   "Cross-sample intra-experiment intensity normalisation",
                   "Log base before protein-level normalisation", "Protein-level intensity generation method",
                   "Imputation method", "Test statistic method",
                   "P value cutoff for ratiometric abundance", "Fold-change cutoff for ratiometric abundance")
info_descriptionCol <- c("PLK 89 LC-MS/MS and LC-MS/MS-FAIMS.",
                         unique_peptides_min, peptide_length_min, peptide_length_max,
                         "Native MaxQuant normalisation", "LoessF",
                         prenormalisation_logbase, "MaxLMQ, sum, average, and median",
                         imputation_mode, p_test,
                         maxP, minFC)
info_furtherCol <- c("H1299 nuclear extracts were immunoprecipitated with an antibody against the protein of interest (pX). Extracts were done either from WT cells, or cells that had been treated with proteinase K for 30 minutes prior to conducting a nuclear extraction. This was done to shave off any extracellular transmembrane proteins and to potentially further refine knowledge on the trafficking of pX, as well as any binding to its extracellular domain. Three experimental variations exist: anti-pX IP after protease K treatment (2 repeats), anti-pX IP without protease treatment (2 samples), and an isotype control IgG IP (1 sample).",
                     "Default: 2.", "Default: 6.", "Default: 25.",
                     "This script builds on evidence.txt and proteinGroups files, which have already been normalised via MaxQuant on the peptide level within each sample.", "Cross-sample intra-experiment intensity normalisation is achieved via LoessF normalisation via R's `limma` package using 3 iterations. This effectively allows us to compare intensities within a single experiment (e.g. control and treatment in FAIMS). Note that this is intra-experiment only - it is generally not recommended to directly compare results from e.g. FAIMS and non-FAIMS MS additively without rigorous controls.",
                     "Default: 2. This should effectively be banal (as long as it is log-transformed), but research tends to use a logbase of 2, and so will I for the sake of convenience.", "A cross-section of MaxLFQ (proteinGroups default) and manual methods (sum, average, median).",
                     "Default: NULL/duplicate. WARNING: when p-values are duplicated and the dataset size is too small (e.g. treatment vs IgG), p values are set to 0.0481 if only duplicated remain, or 0.001234512341231217 if the p-test is failed for some reason; I did my best to lable these in graphs. Proteins are first categorised by the presence of intensities either in the control group (EC, risky_EC), treatment group (Cyt, risky_Cyt), or both (overlap), depending on the presence of intensities in IgG and different sample groups. In the default `NULL/duplicate` setting, missing proteins are duplicated based on their neighbouring repeat from the same sample. 'QRILC' imputation is used in papers (see link in .html RMarkdown report for more information), and is especially appropriate for limit of detection-type data in microarrays and MS - the only word of caution here is that it was used both in the overlap (2 samples of 2 repeats each, cca 100-300 rows), EC, and Cyt (1 sample of 2 repeats each, 100-200 rows) - this is a very low number of repeats and data in general, and the imputation might not be too accurate post grouping. 'Razor' discards all proteins were even a single NA value is present for each group - this is the strictest setting, and as such should generate the most trustworthy data with the pitfall of producing a smaller number of outputs.", "'ROTS' stands for Reproducibility Optimised Test Statistic, and has been shown to perform well in MS-type data as well as for the microarray data it was originally developed for. 't-test' stands for a Students' or Welch's T-test (automatically applied depending on post-F-test heteroscedasticity) with a Benjamini-Hochberg multiple-testing correction based off of the 'p_test_FC_cutoff' metric.",
                     "Maximum allowed (adjusted) p value for abundance calculations. Also functions as a cutoff for designating proteins to be web-scraped off of UniProt, as well as a +/- line in the resulting volcano plot.", "Default: 1.5 (i.e. 50% more abundant than in other sample). Minimum required pre-log abundance fold change (FC) for abundance calculations in p-statistic tests. Also functions as a cutoff for designating proteins to be web-scraped off of UniProt, as well as a +/- line in the resulting volcano plot.")
info_xlsx <- data.frame("Variable" = info_namesCol, 
                        "Value" = info_descriptionCol, 
                        "Details" = info_furtherCol)

### individual abundance lists, along with headlines ---------------------------------------------------------------------------
abundlist_xlsx <- list()
for (i in 1:length(abundances_list)) {
    # # toy data
    # i <- 1
    
    # extract description and store it in the outlist as the name of the list
    abundlist_xlsx[[attr(abundances_list[[i]], "description")]] <- abundances_list[[i]][p.value_text != "Non-significant"]
    colnames(abundlist_xlsx[[i]])[grep(x = colnames(abundlist_xlsx[[i]]), pattern = "overlap_info")] <- "overlap_info"   
    
    # reorder cols
    new_order <- c("protein_main", "overlap_info", 
                   base::setdiff(names(abundlist_xlsx[[i]]), c("protein_main", "overlap_info")))
    abundlist_xlsx[[i]] <- abundlist_xlsx[[i]][, ..new_order] %>% 
        setorder(overlap_info, protein_main)
}

### 1-on-1 abundance intersects between the same ICMs in FAIMS and non-FAIMS datasets ----------------------------------------
## overlap
for (ol in c("overlap", "EC", "Cyt")){
    # # toy data
    # ol <- "overlap"
    
    temp_xsection <- list()
    
    for (i in 1:(length(abundances_list)/2)) {
        # # toy data
        # i <- 1
        
        # setup list appending indexer
        n <- 2*i - 1
        
        # generate intersect
        temp_intersect_gene <- base::intersect(abundlist_xlsx[[n]][overlap_info == ol]$gene,
                                         abundlist_xlsx[[n + 1]][overlap_info == ol]$gene)
        temp_intersect_location <- abundlist_xlsx[[n]][overlap_info == ol & gene %in% temp_intersect_gene]$p.value_text
        temp_intersect_info <- mapply(paste0, temp_intersect_gene, " (", temp_intersect_location, ")", SIMPLIFY = FALSE)
        if (length(temp_intersect_info) == 0) temp_intersect_info <- NA
        
        # extract cross-section name and add it into the outlist 
        temp_xsection[[paste(names(abundlist_xlsx)[n], "X", names(abundlist_xlsx)[n + 1])]] <- temp_intersect_info
    }
        
    # Dynamically create the list name, assign it
    assign(paste0("abundXsect_1_xlsx_", ol), temp_xsection, envir = .GlobalEnv)
}


### total FAIMS and non-FAIMS intersects -----------------------------------------------------------------------------------------------
numlist <- 1:length(abundances_list)

for (ol in c("overlap", "EC", "Cyt")){
    # # toy data
    # ol <- "overlap"
    
    temp_xsection <- list()
    # Loop through the categories (e.g., "Total intersects between all methods, FAIMS and non-FAIMS")
    for (category in c("Total intersects between all methods, FAIMS and non-FAIMS",
                       "LC-MS/MS total intersects",
                       "LC-MS/MS-FAIMS total intersects")) {
        # # toy data
        # category <- "LC-MS/MS total intersects"
        
        # Determine the relevant data frames based on the category
        if (category == "Total intersects between all methods, FAIMS and non-FAIMS") {
            temp_dflist <- abundlist_xlsx
        } else if (category == "LC-MS/MS total intersects") {
            temp_dflist <- abundlist_xlsx[numlist[numlist %% 2 != 0]]
        } else if (category == "LC-MS/MS-FAIMS total intersects") {
            temp_dflist <- abundlist_xlsx[numlist[numlist %% 2 == 0]]
        }
      
        # Extract the genes and annotations (p.value_text) for this category
        temp_intersect_gene <- Reduce(base::intersect, lapply(temp_dflist, function (dt) dt[overlap_info == ol]$gene))
        temp_intersect_location <- lapply(temp_intersect_gene, function (cg) {
            annotations <- sapply(abundlist_xlsx, function (df) return (df[gene == cg]$p.value_text))
            unique_annotations <- unique(unlist(annotations)) %>%
                .[. != "" & !is.na(.)] 
            paste(unique_annotations, collapse = "/")
        })
        
        # generate final result
        temp_intersect_info <- mapply(paste0, temp_intersect_gene, " (", temp_intersect_location, ")", SIMPLIFY = FALSE)
        
        # Store the result in the list
        temp_xsection[[category]] <- temp_intersect_info
    }
    
    # Dynamically create the list name, assign it
    assign(paste0("abundXsect_2_xlsx_", ol), temp_xsection, envir = .GlobalEnv)
}


### FAIMS/non-FAIMS intersect combinatorics -----------------------------------------------------------------------------------
for (ol in c("overlap", "EC", "Cyt")){
    # # toy data
    # ol <- "overlap"
    
    temp_xsection <- list()
    # Loop through combination sizes (1 to 4)
    for (size in 2:3) {
        indices_combinations <- combn(length(abundlist_xlsx)/2, size)
          
        # Loop through combinations and find intersections
        for (i in 1:ncol(indices_combinations)) {
            # # toy data
            # size <- 2
            # i <- 5
            
            indices <- indices_combinations[, i]
            combined_list <- get(paste0("abundXsect_1_xlsx_", ol))[indices]
            names(combined_list) <- str_replace(names(combined_list), ".*-(\\w+)$", "intersect-\\1")
            intersection <- Reduce(base::intersect, combined_list)
            
            # Store intersection based on names
            temp_xsection[[paste(names(combined_list), collapse = " XXX ")]] <- intersection
        }
    }
    
    # Dynamically create the list name, assign it
    assign(paste0("abundXsect_3_xlsx_", ol), temp_xsection, envir = .GlobalEnv)
}


### risky_EC/Cyt data table intersect combinatorics 1 on 1 -----------------------------------------------------------------------------------
for (ol in c("risky_EC", "risky_Cyt")) {
    # # toy data
    # ol <- "overlap"
    
    temp_xsection <- list()
    
    for (i in 1:(length(abundances_list)/2)) {
        # # toy data
        # i <- 1
        
        # setup list appending indexer
        n <- 2*i - 1
        
        # generate intersect
        temp_intersect_gene <- base::intersect(abundlist_xlsx[[n]][overlap_info == ol]$gene,
                                         abundlist_xlsx[[n + 1]][overlap_info == ol]$gene)
        
        # extract cross-section name and add it into the outlist 
        temp_xsection[[paste(names(abundlist_xlsx)[n], "X", names(abundlist_xlsx)[n + 1])]] <- temp_intersect_gene
    }
        
    # Dynamically create the list name, assign it
    assign(paste0("dtXsect_1_xlsx_", ol), temp_xsection, envir = .GlobalEnv)
}

### risky_EC/Cyt data table intersect combinatorics total FAIMS/non-FAIMS ------------------------------------------------------------
for (ol in c("risky_EC", "risky_Cyt")) {
    # # toy data
    # ol <- "overlap"
    
    temp_xsection <- list()
    # Loop through the categories (e.g., "Total intersects between all methods, FAIMS and non-FAIMS")
    for (category in c("Total intersects between all methods, FAIMS and non-FAIMS",
                       "LC-MS/MS total intersects",
                       "LC-MS/MS-FAIMS total intersects")) {
        # # toy data
        # category <- "LC-MS/MS total intersects"
        
        # Determine the relevant data frames based on the category
        if (category == "Total intersects between all methods, FAIMS and non-FAIMS") {
            temp_dflist <- abundlist_xlsx
        } else if (category == "LC-MS/MS total intersects") {
            temp_dflist <- abundlist_xlsx[numlist[numlist %% 2 != 0]]
        } else if (category == "LC-MS/MS-FAIMS total intersects") {
            temp_dflist <- abundlist_xlsx[numlist[numlist %% 2 == 0]]
        }
      
        # Extract the intersect genes and store the result in the list
        temp_xsection[[category]] <- Reduce(base::intersect, lapply(temp_dflist, function (dt) dt[overlap_info == ol]$gene))
    }
    
    # Dynamically create the list name, assign it
    assign(paste0("dtXsect_2_xlsx_", ol), temp_xsection, envir = .GlobalEnv)
}


### risky_EC/Cyt data table intersect combinatorics 1 on many (common/FAIMS overlap combinatorics) ----------------------------------------------------
for (ol in c("risky_EC", "risky_Cyt")) {
    # # toy data
    # ol <- "overlap"
    
    temp_xsection <- list()
    # Loop through combination sizes (1 to 4)
    for (size in 2:3) {
        indices_combinations <- combn(length(abundlist_xlsx)/2, size)
          
        # Loop through combinations and find intersections
        for (i in 1:ncol(indices_combinations)) {
            # # toy data
            # size <- 2
            # i <- 5
            
            indices <- indices_combinations[, i]
            combined_list <- get(paste0("dtXsect_1_xlsx_", ol))[indices]
            names(combined_list) <- str_replace(names(combined_list), ".*-(\\w+)$", "intersect-\\1")
            intersection <- Reduce(base::intersect, combined_list)
            
            # Store intersection based on names
            temp_xsection[[paste(names(combined_list), collapse = " XXX ")]] <- intersection
        }
    }
    
    # Dynamically create the list name, assign it
    assign(paste0("dtXsect_3_xlsx_", ol), temp_xsection, envir = .GlobalEnv)
}
```


### 2.8.2 Generate an Excel workbook containing a summary of this data can be found in the folder along with this document.
```{r 10_make_out_report, warning=FALSE, message=FALSE}
### Return outputs as xlsx workbooks ------------------------------------------------------------------------------------------------
## Setup
# Define the filename for the Excel document
outdir_xlsx <- paste0(out_reports, session_name, "/")
filename <- paste0(outdir_xlsx, session_name, ".xlsx")
if (dir.exists(outdir_xlsx) == FALSE) dir.create(outdir_xlsx, recursive = T)

# Create a new workbook with styles
wb <- wb_workbook(creator = "Tomas Martak")$
    add_dxfs_style(name = "negStyle", font_color = wb_color(hex = "#9C0006"), bg_fill = wb_color(hex = "#FFC7CE"))$
    add_dxfs_style(name = "posStyle", font_color = wb_color(hex = "#006100"), bg_fill = wb_color(hex = "#C6EFCE"))$
    add_dxfs_style(name = "noCtrlStyle", font_color = wb_color(hex = "#735A00"), bg_fill = wb_color(hex = "#FFC500"))

# generate colour guide
colguide <- list("Log2(intensities) > 0 after baseline (IgG) subtraction." = 5,
                 "Log2(intensities) < 0 after baseline (IgG) subtraction." = -5,
                 "Log2(intensities) > 10: no baseline (IgG) intensity found for the given protein, or no baseline discounted due to different type of data (EC/Cyt)." = 11)


## 1st Sheet: info_xlsx as a data frame ###########################################################################
wb <- wb$
    add_worksheet("Settings")$
    add_data(x = info_xlsx)$
    add_font(dims = "A1:C1", bold = T, color = wb_color("#c3c0ff"))$ # font for description
    add_fill(dims = "A1:C1", color = wb_color("#0800b8"))$ # fill for data
    set_col_widths(cols = "A:C", widths = "auto") # autoscale column widths


## 2nd Sheet: abundlist_xlsx as a list of data frames #############################################################
# add abundance list
wb <- wb$add_worksheet(paste0("Abundance Lists"))
row_num <- 1
for (i in 1:length(abundlist_xlsx)) {
    # # toy data
    # i <- 1
    # row_num <- 1

    # Write the element name in bold, and element contents starting from the second row
    df_dims <- paste0("C", row_num + 2, ":H", row_num + nrow(abundlist_xlsx[[i]]) + 1)
    FC_dims <- paste0("I", row_num + 2, ":I", row_num + nrow(abundlist_xlsx[[i]]) + 1)
    title_dims <- paste0("A", row_num + 1, ":P", row_num + 1)
    wb <- wb$
        add_data(sheet = 2, x = names(abundlist_xlsx)[i], startCol = 1, startRow = row_num)$ # description
            add_font(dims = paste0("A", row_num), bold = T, color = wb_color("#c3c0ff"))$ # font for description
            add_fill(dims = paste0("A", row_num), color = wb_color("#0800b8"))$ # fill for data
        add_data(x = abundlist_xlsx[[i]], startCol = 1, startRow = row_num + 1)$ # dataframe with colnames in 1st row
            add_font(dims = title_dims, bold = T)$ # bold font for df titles
            add_border(dims = title_dims, right_border = NULL, left_border = NULL, top_border = NULL, bottom_border = "thin")$ # border below titles
            add_conditional_formatting(dims = df_dims, rule = ">=0", style = "posStyle")$ # for pos intensities
            add_conditional_formatting(dims = df_dims, rule = "<0", style = "negStyle")$ # for neg intensities
            add_conditional_formatting(dims = FC_dims, rule = ">=0", style = "posStyle")$ # for pos FCs
            add_conditional_formatting(dims = FC_dims, rule = "<0", style = "negStyle")$ # for neg FCs
            add_conditional_formatting(dims = df_dims, rule = ">10", style = "noCtrlStyle")$
            add_border(dims = paste0("B", row_num + 2, ":B", row_num + nrow(abundlist_xlsx[[i]]) + 1), 
                       right_border = "thick", left_border = NULL, top_border = NULL, bottom_border = NULL)$
            add_border(dims = paste0("F", row_num + 2, ":F", row_num + nrow(abundlist_xlsx[[i]]) + 1), 
                       right_border = "thin", left_border = NULL, top_border = NULL, bottom_border = NULL)$    
            add_border(dims = paste0("H", row_num + 2, ":H", row_num + nrow(abundlist_xlsx[[i]]) + 1), 
                       right_border = "thick", left_border = NULL, top_border = NULL, bottom_border = NULL)$
            add_border(dims = paste0("I", row_num + 2, ":I", row_num + nrow(abundlist_xlsx[[i]]) + 1), 
                       right_border = "thick", left_border = NULL, top_border = NULL, bottom_border = NULL)
            
    vignette("conditional-formatting")
    # Add a black row as a separator
    row_num <- row_num + nrow(abundlist_xlsx[[i]]) + 2
    wb <- wb$add_fill(sheet = 2, dims = wb_dims(rows = row_num, cols = "A:O"), color = wb_color(hex = "#000000"))
    row_num <- row_num + 1
}

# Final formatting
wb <- wb$
    add_numfmt(sheet = 2, dims = "C1:K1000", numfmt = "0.000")$ # number format: 3 decimal points, show 0
    set_col_widths(cols = "A:P", widths = "auto") # autoscale column widths

# add colour legend
for (i in 1:length(colguide)) {
    row_num <- row_num + 1
    df_dims <- paste0("A", row_num, ":B", row_num)
    # Write the element name in bold, and element contents starting from the second row
    wb <- wb$
        add_data(sheet = 2, x = names(colguide[i]), startCol = 2, startRow = row_num)$ # add description
        add_data(x = colguide[[i]], startCol = 1, startRow = row_num)$ # add value for font colouring
            add_conditional_formatting(dims = df_dims, rule = paste0("$A", row_num, ">=0"), style = "posStyle")$
            add_conditional_formatting(dims = df_dims, rule = paste0("$A", row_num, "<0"), style = "negStyle")$
            add_conditional_formatting(dims = df_dims, rule = paste0("$A", row_num, ">10"), style = "noCtrlStyle")$
            merge_cells(dims = paste0("B", row_num, ":H", row_num), solve = T)$
            add_border(dims = paste0("B", row_num, ":H", row_num), left_border = "thick")$
            add_border(dims = paste0("A", row_num))
        
}

## 3rd to 5th Sheets: abundXsect_1-3_xlsx as lists of lists of strings ############################################
for (ol in c("overlap", "EC", "Cyt")) {
    # # toy data
    # ol <- 1
    
    row_num <- 1
    temp_ws <- paste0("Intersects ", ol)
    wb <- wb$add_worksheet(temp_ws)
    
    for (i in 1:3) {
        # # toy data
        # i <- 1
        # j <- 1
        
        name_input <- paste0("abundXsect_", i, "_xlsx_", ol)
        # cycle through intersect datasets
        for (j in 1:length(get(name_input))) {
            # append element to workbook
            wb <- wb$
                add_data(temp_ws, x = names(get(name_input)[j]), startCol = 1, startRow = row_num)$ # description
                    add_font(dims = paste0("A", row_num), bold = T, color = wb_color("#c3c0ff"))$ # font for description
                    add_fill(dims = paste0("A", row_num), color = wb_color("#0800b8"))$ # fill for data
                add_data(x = paste0(get(name_input)[[j]]), startCol = 1, startRow = row_num + 1) # list of proteins
            
            # if there is no content in the list element, write NA and colour red
            if (length(get(name_input)[[j]]) == 0) {
                row_num <- row_num + 1
                wb <- wb$add_data(temp_ws, x = "No intersect present", startCol = 1, startRow = row_num)$
                    add_font(dims = paste0("A", row_num), bold = T, color = wb_color("#9C0006"))$ # font for description
                    add_fill(dims = paste0("A", row_num), bold = T, color = wb_color("#FFC7CE")) # fill for description
            }
      
            # Add a black row as a separator
            row_num <- row_num + length(get(name_input)[[j]]) + 2
            wb <- wb$add_fill(temp_ws, dims = wb_dims(rows = row_num, cols = "A:C"), color = wb_color(hex = "#000000"))
            row_num <- row_num + 1
        }
    }

    # Final formatting
    wb <- wb$set_col_widths(temp_ws, cols = "A:C", widths = "auto") # autoscale column widths
}


## 6th to 7th Sheets: abundXsect_1-3_xlsx as lists of lists of strings ############################################
for (ol in c("risky_EC", "risky_Cyt")) {
    # # toy data
    # ol <- "risky_EC"
    
    row_num <- 1
    temp_ws <- paste0("Intersects ", ol)
    wb <- wb$add_worksheet(temp_ws)
    
    for (i in 1:3) {
        # # toy data
        # i <- 1
        # j <- 1
        
        name_input <- paste0("dtXsect_", i, "_xlsx_", ol)
        # cycle through intersect datasets
        for (j in 1:length(get(name_input))) {
            # append element to workbook
            wb <- wb$
                add_data(temp_ws, x = names(get(name_input)[j]), startCol = 1, startRow = row_num)$ # description
                    add_font(dims = paste0("A", row_num), bold = T, color = wb_color("#c3c0ff"))$ # font for description
                    add_fill(dims = paste0("A", row_num), color = wb_color("#0800b8"))$ # fill for data
                add_data(x = paste0(get(name_input)[[j]]), startCol = 1, startRow = row_num + 1) # list of proteins
            
            # if there is no content in the list element, write NA and colour red
            if (length(get(name_input)[[j]]) == 0) {
                row_num <- row_num + 1
                wb <- wb$add_data(temp_ws, x = "No intersect present", startCol = 1, startRow = row_num)$
                    add_font(dims = paste0("A", row_num), bold = T, color = wb_color("#9C0006"))$ # font for description
                    add_fill(dims = paste0("A", row_num), bold = T, color = wb_color("#FFC7CE")) # fill for description
            }
      
            # Add a black row as a separator
            row_num <- row_num + length(get(name_input)[[j]]) + 2
            wb <- wb$add_fill(temp_ws, dims = wb_dims(rows = row_num, cols = "A:C"), color = wb_color(hex = "#000000"))
            row_num <- row_num + 1
        }
    }

    # Final formatting
    wb <- wb$set_col_widths(temp_ws, cols = "A:C", widths = "auto") # autoscale column widths
}

# Save the workbook to the specified filename
wb_save(wb, path = filename, overwrite = T)
```

